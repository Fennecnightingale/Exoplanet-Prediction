{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import exodata\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import exodata.astroquantities as aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(x):\n",
    "    \"\"\"pass in a value you'd like to check to see if it is not a number, not to be confused with .isna() which returns checks if null\"\"\"\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfNames(names):\n",
    "    \"\"\"Pass in a string from dataframe that has names surrounded by parentheses you'd like to extract the names from\n",
    "    ex: stars['name'] = Star('11 com b') -> stars['name'] = '11 com b'\"\"\"\n",
    "    temp = \"\"\n",
    "    while len(names) > 2:\n",
    "        start = names.find('(') + 2\n",
    "        end = names.find(')') - 1\n",
    "        temp += names[start:end] if len(temp) == 0 else \", \" + names[start:end]\n",
    "        names = names[end + 2 :]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findGLName(primary, alts):\n",
    "    \"\"\"extract Gliese name & ID number and arrange them in formatting that matches current standard stellar naming conventions\n",
    "    ex: stars['altnames'] = ['11 com b', 'Gliese 234', 'HD137'] -> stars['GL'] = 'GL 234'\"\"\"\n",
    "    prefixes = [\"GL \", \"Gliese \", \"NN \", \"WO \", \"GJ \"]\n",
    "    name = \"\"\n",
    "    for i in range(len(prefixes)):\n",
    "        if primary.startswith(prefixes[i]):\n",
    "            name = primary\n",
    "            break\n",
    "    if name == \"\" and alts != \"\":\n",
    "        for i in range(len(alts)):\n",
    "            for j in range(len(prefixes)):\n",
    "                if alts[i].startswith(prefixes[j]):\n",
    "                    name = alts[i]\n",
    "                    break\n",
    "            if name != \"\":\n",
    "                break\n",
    "    if name == \"\":\n",
    "        return np.nan\n",
    "    if name.startswith(\"GL\"):\n",
    "        name = \"Gl\" + name[2:]\n",
    "    elif name.startswith(\"WO\"):\n",
    "        name = \"Wo\" + name[2:]\n",
    "    elif name.startswith(\"Gliese\"):\n",
    "        name = \"GJ\" + name[6:]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOtherName(check, primary, alts):\n",
    "    \"\"\"extract other names & ID number and arrange them in formatting that matches current standard stellar naming conventions\n",
    "    ex: stars['altnames'] = ['11 com b', 'Gliese 234', 'HD137'] -> stars['HD'] = '137'\"\"\"\n",
    "    name = \"\"\n",
    "    if primary.startswith(check):\n",
    "        name = primary[len(check) + 1:]\n",
    "    if name == \"\" and alts == \"\":\n",
    "        return np.nan\n",
    "    for i in range(len(alts)):\n",
    "        if alts[i].startswith(check):\n",
    "            name = alts[i][len(check) + 1:]\n",
    "    if name == \"\":\n",
    "        return np.nan\n",
    "    while re.search(\"\\D\", name):\n",
    "        name = name[:-1]\n",
    "    return float(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of telescope data for nearly 200k stars \n",
    "star_csv = pd.read_csv('hygdata_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the most current data from the Open Exoplanet Catalouge\n",
    "exocat = exodata.load_db_from_url('https://github.com/OpenExoplanetCatalogue/oec_gzip/raw/master/systems.xml.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign names to tree branches we'll be using \n",
    "planets = exocat.planets\n",
    "systems = exocat.systems\n",
    "stars = exocat.stars\n",
    "binary = exocat.binaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets[0].system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove every bit of info from the xml and transfer it to a dataframe, first we'll be making each of the branches into it's own dictionary \n",
    "sys_dict = {}\n",
    "bn_dict = {}\n",
    "star_dict = {}\n",
    "pln_dict = {}\n",
    "\n",
    "#then we iterate over each element in the branch and fill the dictionaries with the information they contain, data is stored in this tree\n",
    "#in both callable methods, and within a dictionary within one of those methods, which makes it kind of a mess to extract \n",
    "#also the module is written to raise errors instead of returning nothing, so everything has to be wrapped in a try statement with nan being fill if not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try these with continue instead of the except statement and see what if anything changes, might be able to shorten \n",
    "# also change to i in range \n",
    "i = 0 \n",
    "while i < 3307:\n",
    "    sys_dict[i] = {}\n",
    "    try:\n",
    "        sys_dict[i]['right_ascension'] = systems[i].ra\n",
    "    except:\n",
    "        sys_dict[i]['right_ascension'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['altnames'] = systems[i].altnames\n",
    "    except:\n",
    "        sys_dict[i]['altnames'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['list'] = systems[i].list\n",
    "    except:\n",
    "        sys_dict[i]['list'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['declination'] = systems[i].dec\n",
    "    except:\n",
    "        sys_dict[i]['declination'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['distance'] = systems[i].d\n",
    "    except:\n",
    "        sys_dict[i]['distance'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['child_stars_binaries'] = systems[i].stars\n",
    "    except:\n",
    "        sys_dict[i]['child_stars_binaries'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['epoch'] = systems[i].epoch\n",
    "    except:\n",
    "        sys_dict[i]['epoch'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['name'] = systems[i].name\n",
    "    except:\n",
    "        sys_dict[i]['name'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['all_children'] = systems[i].children\n",
    "    except:\n",
    "        sys_dict[i]['all_children'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['flags'] = systems[i].flags\n",
    "    except:\n",
    "        sys_dict[i]['flags'] = np.nan\n",
    "    i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try these with continue instead of the except statement and see what if anything changes, might be able to shorten \n",
    "# also change to i in range \n",
    "i = 0 \n",
    "while i < 202:\n",
    "    bn_dict[i] = {}\n",
    "    bn_dict[i]['alt_names'] = binary[i].params['altnames']\n",
    "    bn_dict[i]['flags'] = binary[i].flags\n",
    "    bn_dict[i]['system'] = binary[i].system\n",
    "    try:\n",
    "        bn_dict[i]['names'] = binary[i].params['name']\n",
    "    except:\n",
    "        bn_dict[i]['names'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['list'] = binary[i].params['list']\n",
    "    except:\n",
    "        bn_dict[i]['list'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['separation'] = binary[i].params['separation']\n",
    "    except:\n",
    "        bn_dict[i]['separation'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['position_angle'] = binary[i].params['positionangle']\n",
    "    except:\n",
    "        bn_dict[i]['position_angle'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['mass'] = binary[i].params['mass']\n",
    "    except:\n",
    "        bn_dict[i]['mass'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['magUltraviolet'] = binary[i].params['magU']\n",
    "    except:\n",
    "        bn_dict[i]['magUltraviolet'] = np.nan\n",
    "    try: \n",
    "        bn_dict[i]['magBlue'] = binary[i].params['magB']\n",
    "    except:\n",
    "        bn_dict[i]['magBlue'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['magH_nearinf'] = binary[i].params['magH']\n",
    "    except:\n",
    "        bn_dict[i]['magH_nearinf'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['magInfared'] = binary[i].params['magI']\n",
    "    except: \n",
    "        bn_dict[i]['magInfared'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['magJ_nearinf'] = binary[i].params['magJ']\n",
    "    except: \n",
    "        bn_dict[i]['magJ_nearinf'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['magK_nearinf'] = binary[i].params['magK']\n",
    "    except: \n",
    "        bn_dict[i]['magK_nearinf'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['magVisual'] = binary[i].params['magV']\n",
    "    except: \n",
    "        bn_dict[i]['magVisual'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['magL_nq_midinfared'] = binary[i].params['magL']\n",
    "    except:\n",
    "        bn_dict[i]['magL_nq_midinfared'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['magM_midinfared'] = binary[i].params['magM']\n",
    "    except: \n",
    "        bn_dict[i]['magM_midinfared'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['magN_midinfared'] = binary[i].params['magN']\n",
    "    except:\n",
    "        bn_dict[i]['magN_midinfared'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['distance'] = binary[i].d\n",
    "    except:\n",
    "        bn_dict[i]['distance'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['periastron'] = binary[i].periastron\n",
    "    except:\n",
    "        bn_dict[i]['periastron'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['right_ascension'] = binary[i].ra\n",
    "    except:\n",
    "        bn_dict[i]['right_ascension'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['declination'] = binary[i].dec\n",
    "    except:\n",
    "        bn_dict[i]['declination'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['inclination'] = binary[i].i\n",
    "    except:\n",
    "        bn_dict[i]['inclination'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['parent_obj'] = binary[i].parent\n",
    "    except: \n",
    "        bn_dict[i]['parent_obj'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['child_obj'] = binary[i].children\n",
    "    except: \n",
    "        bn_dict[i]['child_obj'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['stars'] = binary[i].stars\n",
    "    except: \n",
    "        bn_dict[i]['stars'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['period'] = binary[i].P\n",
    "    except: \n",
    "        bn_dict[i]['period'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['semi_major_axis'] = binary[i].a\n",
    "    except: \n",
    "        bn_dict[i]['semi_major_axis'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['eccentricity'] = binary[i].e\n",
    "    except: \n",
    "        bn_dict[i]['eccentricity'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['longitude'] = binary[i].longitude\n",
    "    except: \n",
    "        bn_dict[i]['longitude'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['ascending_node'] = binary[i].ascendingnode\n",
    "    except: \n",
    "        bn_dict[i]['ascending_node'] = np.nan\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try these with continue instead of the except statement and see what if anything changes, might be able to shorten \n",
    "# also change to i in range \n",
    "i = 0 \n",
    "while i < 3505:\n",
    "    star_dict[i] = {}\n",
    "    try:\n",
    "        star_dict[i]['spectral_type'] = stars[i].params['spectraltype']\n",
    "    except: \n",
    "        star_dict[i]['spectral_type'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['temp'] = stars[i].params['temperature']\n",
    "    except:\n",
    "        star_dict[i]['temp'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['metallicity'] = stars[i].params['metallicity']\n",
    "    except:\n",
    "        star_dict[i]['metallicity'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['altnames'] = stars[i].params['altnames']\n",
    "    except:\n",
    "        star_dict[i]['altnames'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['mass'] = stars[i].params['mass']\n",
    "    except:\n",
    "        star_dict[i]['mass'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magUltraviolet'] = stars[i].params['magU']\n",
    "    except:\n",
    "        star_dict[i]['magUltraviolet'] = np.nan\n",
    "    try: \n",
    "        star_dict[i]['magBlue'] = stars[i].params['magB']\n",
    "    except:\n",
    "        star_dict[i]['magBlue'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magH_nearinfared'] = stars[i].params['magH']\n",
    "    except:\n",
    "        star_dict[i]['magH_nearinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magInfared'] = stars[i].params['magI']\n",
    "    except: \n",
    "        star_dict[i]['magInfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magJ_nearinfared'] = stars[i].params['magJ']\n",
    "    except: \n",
    "        star_dict[i]['magJ_nearinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magK_nearinfared'] = stars[i].params['magK']\n",
    "    except: \n",
    "        star_dict[i]['magK_nearinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magVisual'] = stars[i].params['magV']\n",
    "    except: \n",
    "        star_dict[i]['magVisual'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magL_nq_midinfared'] = stars[i].params['magL']\n",
    "    except:\n",
    "        star_dict[i]['magL_nq_midinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magM_midinfared'] = stars[i].params['magM']\n",
    "    except: \n",
    "        star_dict[i]['magM_midinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magN_midinfared'] = stars[i].params['magN']\n",
    "    except:\n",
    "        star_dict[i]['magN_midinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['distance'] = stars[i].d\n",
    "    except:\n",
    "        star_dict[i]['distance'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['periastron'] = stars[i].params['periastron']\n",
    "    except:\n",
    "        star_dict[i]['periastron'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['right_ascension'] = stars[i].ra\n",
    "    except:\n",
    "        star_dict[i]['right_ascension'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['declination'] = stars[i].dec\n",
    "    except:\n",
    "        star_dict[i]['declination'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['parent_obj'] = stars[i].parent\n",
    "    except: \n",
    "        star_dict[i]['parent_obj'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['child_obj'] = stars[i].children\n",
    "    except: \n",
    "        star_dict[i]['child_obj'] = np.nan\n",
    "    try: \n",
    "        star_dict[i]['planet1type'] = stars[i].children[0].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet1type'] = np.nan  \n",
    "    try: \n",
    "        star_dict[i]['planet2type'] = stars[i].children[1].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet2type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet3type'] = stars[i].children[2].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet3type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet4type'] = stars[i].children[3].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet4type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet5type'] = stars[i].children[4].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet5type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet6type'] = stars[i].children[5].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet6type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet7type'] = stars[i].children[6].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet7type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet8type'] = stars[i].children[7].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet8type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet9type'] = stars[i].children[8].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet9type'] = np.nan \n",
    "    star_dict[i]['proper'] = stars[i].name\n",
    "    star_dict[i]['flags'] = stars[i].flags\n",
    "    star_dict[i]['system'] = stars[i].system\n",
    "    star_dict[i]['radius'] = stars[i].R\n",
    "    star_dict[i]['age'] = stars[i].age\n",
    "    star_dict[i]['hip'] = findOtherName(\"HIP \", star_dict[i]['proper'], star_dict[i]['altnames'])\n",
    "    star_dict[i]['hd'] = findOtherName(\"HD \", star_dict[i]['proper'], star_dict[i]['altnames'])\n",
    "    star_dict[i]['hr'] = findOtherName(\"HR \", star_dict[i]['proper'], star_dict[i]['altnames'])\n",
    "    star_dict[i]['gl'] = findGLName(star_dict[i]['proper'], star_dict[i]['altnames'])\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try these with continue instead of the except statement and see what if anything changes, might be able to shorten \n",
    "# also change to i in range \n",
    "i = 0\n",
    "while i < 4499:\n",
    "    pln_dict[i] = {}\n",
    "    pln_dict[i]['flags'] = planets[i].flags\n",
    "    pln_dict[i]['radius'] = planets[i].R\n",
    "    pln_dict[i]['orbital_inclination'] = planets[i].i\n",
    "    pln_dict[i]['seperation'] = planets[i].seperation\n",
    "    pln_dict[i]['age'] = planets[i].age\n",
    "    pln_dict[i]['transit_time'] = planets[i].transittime\n",
    "    pln_dict[i]['longitude'] = planets[i].longitude\n",
    "    pln_dict[i]['ascending_node'] = planets[i].ascendingnode\n",
    "    pln_dict[i]['discovery_method'] = planets[i].discoveryMethod\n",
    "    pln_dict[i]['discovery_year'] = planets[i].discoveryYear\n",
    "    pln_dict[i]['description '] = planets[i].description\n",
    "    pln_dict[i]['alt_names'] = planets[i].params['altnames']\n",
    "    pln_dict[i]['list'] = planets[i].params['list']\n",
    "    try:\n",
    "        pln_dict[i]['system'] = getListOfNames(str(planets[i].system))\n",
    "    except:\n",
    "        pln_dict[i]['system'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['name'] = planets[i].name\n",
    "    except:\n",
    "        pln_dict[i]['name'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['type'] = planets[i].type()\n",
    "    except:\n",
    "        pln_dict[i]['type'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['mass'] = planets[i].params['mass']\n",
    "    except:\n",
    "        pln_dict[i]['mass'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['semi_major_axis'] = planets[i].params['semimajoraxis']\n",
    "    except:\n",
    "        pln_dict[i]['semi_major_axis'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['orbital_period'] = planets[i].params['period']\n",
    "    except:\n",
    "        pln_dict[i]['orbital_period'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['periastron'] = planets[i].params['periastron']\n",
    "    except:\n",
    "        pln_dict[i]['orbital_period'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['periastron_time'] = planets[i].params['periastrontime']\n",
    "    except:\n",
    "        pln_dict[i]['periastron_time'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['eccentricity'] = planets[i].params['eccentricity']\n",
    "    except:\n",
    "        pln_dict[i]['eccentricity'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['distance'] = planets[i].d\n",
    "    except:\n",
    "        pln_dict[i]['distance'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['periastron'] = planets[i].params['periastron']\n",
    "    except:\n",
    "        pln_dict[i]['periastron'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['temp'] = planets[i].T\n",
    "    except:\n",
    "        pln_dict[i]['temp'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['right_ascension'] = planets[i].ra\n",
    "    except:\n",
    "        pln_dict[i]['right_ascension'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['declination'] = planets[i].dec\n",
    "    except:\n",
    "        pln_dict[i]['declination'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['parent_obj'] = planets[i].parent\n",
    "    except: \n",
    "        pln_dict[i]['parent_obj'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['star'] = getListOfNames(str(planets[i].star))\n",
    "    except: \n",
    "        pln_dict[i]['star'] = np.nan\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all of my dictionaries to dataframes so I can work with them in pandas \n",
    "pdf = pd.DataFrame(pln_dict)\n",
    "sdf = pd.DataFrame(star_dict)\n",
    "bdf = pd.DataFrame(bn_dict)\n",
    "sysdf = pd.DataFrame(sys_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realign them so my columns are on top and rows go downward \n",
    "planets = pdf.transpose()\n",
    "stars = sdf.transpose()\n",
    "systems = bdf.transpose()\n",
    "binaries = sysdf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly check over data and drop columns that are already noticably unusable \n",
    "planets = planets.drop(labels=['age','seperation','longitude','ascending_node','periastron_time', 'discovery_year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets['system']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to get name here? \n",
    "# clean up planets to correctly cast columns to dtypes\n",
    "# planets['system'] = planets['system'].str.strip(to_strip=\"System('\")\n",
    "# planets['system'] = planets['system'].str.strip(to_strip=\"')\")\n",
    "planets['radius'] = planets['radius'].str.strip(to_strip=\" R_j\")\n",
    "planets['orbital_inclination'] = planets['orbital_inclination'].str.strip(to_strip=\" deg\")\n",
    "planets['transit_time'] = planets['transit_time'].str.strip(to_strip=\" JD\")\n",
    "# planets['parent_obj'] = planets['parent_obj'].str.strip(\"Star('\")\n",
    "# planets['parent_obj'] = planets['parent_obj'].str.strip(\"')\")\n",
    "planets['mass'] = planets['mass'].str.strip(\" M_j\")\n",
    "planets['semi_major_axis'] = planets['semi_major_axis'].str.strip(\" au\")\n",
    "planets['orbital_period'] = planets['orbital_period'].str.strip(\" d\")\n",
    "planets['periastron'] = planets['periastron'].str.strip(\" deg\")\n",
    "planets['distance'] = planets['distance'].str.strip(\" pc\")\n",
    "planets['temp'] = planets['temp'].str.strip(\" K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all columns to correct dtypes \n",
    "planets['radius'] = planets['radius'].astype(float)\n",
    "planets['orbital_period'] = planets['orbital_period'].astype(float)\n",
    "planets['mass'] = planets['mass'].astype(float)\n",
    "planets['transit_time'] = planets['transit_time'].astype(float)\n",
    "planets['orbital_inclination'] = planets['orbital_inclination'].astype(float)\n",
    "planets['periastron'] = planets['periastron'].astype(float)\n",
    "planets['distance'] = planets['distance'].astype(float)\n",
    "planets['temp'] = planets['temp'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what was I doing here?\n",
    "# did this work?\n",
    "i = 0\n",
    "letter = []\n",
    "for i in range(0, 4499):\n",
    "    letter.append(planets['name'][i][-1:])\n",
    "planets['letter'] = letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and rename planets to be consistent to that you don't end up with 600 dummy variables where you only need 6 \n",
    "planets['letter'].replace(to_replace={'A': 'B', 'a':'B', '1':'B','2':'C', '3':'D', '4':'E', '8':'I'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix individual indices with wonky planet letters\n",
    "planets.iloc[3766] = planets.iloc[3766].replace({'n': 'b'})\n",
    "planets.iloc[4178] = planets.iloc[4178].replace({'o': 'h'})\n",
    "planets.iloc[1669] = planets.iloc[1669].replace({'X': 'd'})\n",
    "planets.iloc[4174] = planets.iloc[4174].replace({'r': 'j'})\n",
    "planets.iloc[4170] = planets.iloc[4170].replace({'y': 'b'})\n",
    "planets.iloc[4175] = planets.iloc[4175].replace({'n': 'f'})\n",
    "planets.iloc[4171] = planets.iloc[4171].replace({'s': 'b'})\n",
    "planets.iloc[4173] = planets.iloc[4173].replace({'s': 'd'})\n",
    "planets.iloc[4176] = planets.iloc[4176].replace({'s': 'f'})\n",
    "planets.iloc[3754] = planets.iloc[3754].replace({'s': 'c'})\n",
    "planets['letter'] = planets['letter'].astype(str)\n",
    "planets['letter'] = planets['letter'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummy variables of other applicable columns \n",
    "planets['confirmed_planet'] = planets['list'].str.contains('Confirmed planets')\n",
    "planets['retracted'] = planets['list'].str.contains('Retracted planet candidate')\n",
    "planets['binary_system'] = planets['list'].str.contains('binary systems')\n",
    "planets = planets.drop('list', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(planets['discovery_method'], drop_first=True)\n",
    "planets = planets.merge(dummies, left_index=True, right_index=True)\n",
    "planets = planets.drop('discovery_method', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change your bools to ints so they're no longer objects \n",
    "planets = planets.replace({True: 1, False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up stars to correctly cast to dtypes \n",
    "stars['radius'] = stars['radius'].str.strip(to_strip=\" R_s\")\n",
    "stars['age'] = stars['age'].str.strip(\" Gyr\")\n",
    "stars['mass'] = stars['mass'].str.strip(\" M_s\")\n",
    "stars['distance'] = stars['distance'].str.strip(\" pc\")\n",
    "stars['temp'] = stars['temp'].str.strip(\" K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot set value on slices of dataframe, so in order to extract the names they need to be turned into a dictionary and merged with original df \n",
    "# going to merge on index, so need index to be something I can pull and add to my dictionary\n",
    "stars = stars.reset_index()\n",
    "star_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names for star objects\n",
    "for i in range(0, 3505):\n",
    "    star_dict[i] = {}\n",
    "    star_dict[i]['child_obj'] = getListOfNames(stars['child_obj'][i])\n",
    "    star_dict[i]['parent_obj'] = getListOfNames(stars['parent_obj'][i])\n",
    "    star_dict[i]['system'] = getListOfNames(stars['system'][i])\n",
    "    star_dict[i]['index'] = stars['index'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into a new dataframe to merge with the old one, drop columns that would otherwise be duplicates, merge on matching index \n",
    "star_dict = pd.DataFrame.from_dict(star_dict)\n",
    "star_dict = star_dict.transpose()\n",
    "stars = stars.drop(['child_obj', 'system', 'parent_obj'], 1)\n",
    "stars = stars.merge(star_dict, on=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with little to no information\n",
    "stars = stars.drop(['magL_nq_midinfared', 'magM_midinfared', 'magN_midinfared', 'periastron'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recast everything as dtypes we can work with \n",
    "stars['radius'] = stars['radius'].astype(float) \n",
    "stars['age'] = stars['age'].astype(float) \n",
    "stars['temp'] = stars['temp'].astype(float) \n",
    "stars['mass'] = stars['mass'].astype(float) \n",
    "stars['distance'] = stars['distance'].astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe turn this into a loop to do it? any way to clean it up \n",
    "# I want to know how many total of each variety of planet each star has, to see if we can predict which type a star with a planet will have based on \n",
    "# its features. I have a maximum of 8 planets in any solar system (excluding pluto which is still on the list as a dwarf)\n",
    "columns = {'Cold Jupiter':'CJ', 'Cold Neptune':'CN', 'Cold Super-Earth':'CE', 'Hot Jupiter':'HE', \n",
    "           'Hot Neptune':'HN', 'Hot Super-Earth':'HSE', 'None Jupiter':'JUP', 'None Neptune':'NEP', \n",
    "           'None Super-Earth':'SE', 'Warm Jupiter':'WJ', 'Warm Neptune':'WN', 'Warm Super-Earth':'WSE'}\n",
    "\n",
    "dumms1 = pd.get_dummies(stars['planet1type'])\n",
    "dumms1 = dumms1.rename(columns=columns)\n",
    "dumms2 = pd.get_dummies(stars['planet2type'])\n",
    "dumms2 = dumms2.rename(columns=columns)\n",
    "dumms3 = pd.get_dummies(stars['planet3type'])\n",
    "dumms3 = dumms3.rename(columns=columns)\n",
    "dumms4 = pd.get_dummies(stars['planet4type'])\n",
    "dumms4 = dumms4.rename(columns=columns)\n",
    "dumms5 = pd.get_dummies(stars['planet5type'])\n",
    "dumms5 = dumms5.rename(columns=columns)\n",
    "dumms6 = pd.get_dummies(stars['planet6type'])\n",
    "dumms6 = dumms6.rename(columns=columns)\n",
    "dumms7 = pd.get_dummies(stars['planet7type'])\n",
    "dumms7 = dumms7.rename(columns=columns)\n",
    "dumms8 = pd.get_dummies(stars['planet8type'])\n",
    "dumms8 = dumms8.rename(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = dumms1.merge(dumms2, left_index=True, right_index=True, suffixes=('1', '2'))\n",
    "d2 = d1.merge(dumms3, left_index=True, right_index=True)\n",
    "d3 = d2.merge(dumms4, left_index=True, right_index=True, suffixes=('3', '4'))\n",
    "d4 = d3.merge(dumms5, left_index=True, right_index=True)\n",
    "d5 = d4.merge(dumms6, left_index=True, right_index=True, suffixes=('6', '6'))\n",
    "d6 = d5.merge(dumms7, left_index=True, right_index=True)\n",
    "pln_types = d6.merge(dumms8, left_index=True, right_index=True, suffixes=('7', '8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_types = pln_types.astype(float).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_types['WSE8'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_types['CJ'] = pln_types['CJ1'] + pln_types['CJ2'] + pln_types['CJ3'] + pln_types['CJ4'] + pln_types['CJ7'] + pln_types['CJ8'] \n",
    "pln_types['CN'] = pln_types['CN1'] + pln_types['CN2'] + pln_types['CN3'] + pln_types['CN4'] + pln_types['CN_x'] + pln_types['CN_y'] + pln_types['CN'] \n",
    "pln_types['CE'] = pln_types['CE1'] + pln_types['CE2'] + pln_types['CE3'] + pln_types['CE4'] + pln_types['CE'] \n",
    "pln_types['HE'] = pln_types['HE'] \n",
    "pln_types['HN'] = pln_types['HN1'] + pln_types['HN2'] \n",
    "pln_types['HSE'] = pln_types['HSE1'] + pln_types['HSE2'] + pln_types['HSE3'] \n",
    "pln_types['JUP'] = pln_types['JUP1'] + pln_types['JUP2'] + pln_types['JUP3']\n",
    "pln_types['NEP'] = pln_types['NEP1'] + pln_types['NEP2'] + pln_types['NEP']\n",
    "pln_types['SE'] = pln_types['SE1'] + pln_types['SE2'] + pln_types['SE3'] + pln_types['SE4']\n",
    "pln_types['WJ'] = pln_types['WJ1'] + pln_types['WJ2'] + pln_types['WJ3'] + pln_types['WJ4'] \n",
    "pln_types['WN'] = pln_types['WN1'] + pln_types['WN2'] + pln_types['WN3'] + pln_types['WN4']\n",
    "pln_types['WSE'] = pln_types['WSE1'] + pln_types['WSE2'] + pln_types['WSE3'] + pln_types['WSE4'] + pln_types['WSE7'] + pln_types['WSE8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_types = pln_types.drop(columns=['CJ1', 'CN1', 'CE1', 'HN1', 'HSE1', 'JUP1', 'NEP1', 'SE1', 'WJ1', 'WN1', 'WSE1',\n",
    "                     'CJ2', 'CN2', 'CE2', 'HN2', 'HSE2', 'JUP2', 'NEP2', 'SE2', 'WJ2', 'WN2', 'WSE2', 'CJ3', \n",
    "                     'CN3', 'CE3', 'HSE3', 'JUP3', 'SE3', 'WJ3', 'WN3', 'WSE3', 'CJ4', 'CN4', 'CE4', \n",
    "                     'HSE4', 'JUP4', 'SE4', 'WJ4', 'WN4', 'WSE4', 'CJ6', 'CN_x', 'CE6', 'SE6', 'WSE6', 'CJ6',\n",
    "                     'CE6', 'SE6', 'WSE6', 'CJ7', 'CN_y', 'WSE7', 'CJ8', 'WSE8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = stars.merge(pln_types, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaries = binaries.reset_index()\n",
    "binary_dict = {} \n",
    "\n",
    "for i in range(len(binaries['child_obj'])):\n",
    "    binary_dict[i] = {}\n",
    "    binary_dict[i]['child_obj'] = getListOfNames(binaries['child_obj'][i])\n",
    "    binary_dict[i]['system'] = getListOfNames(binaries['system'][i])\n",
    "    binary_dict[i]['stars'] = getListOfNames(binaries['stars'][i])\n",
    "    binary_dict[i]['parent_obj'] = getListOfNames(binaries['parent_obj'][i])\n",
    "    binary_dict[i]['index'] = binaries['index'][i]\n",
    "    \n",
    "binary_dict = pd.DataFrame.from_dict(binary_dict)\n",
    "binary_dict = binary_dict.transpose()\n",
    "binaries = binaries.drop(['child_obj', 'system', 'stars'], 1)\n",
    "binaries = binaries.merge(binary_dict, on=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaries = binaries.drop(['list'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaries['distance'] = binaries['distance'].str.strip(\" pc\")\n",
    "binaries['distance'] = binaries['distance'].astype(float)\n",
    "binaries['separation'] = binaries['separation'].str.strip(\" au\")\n",
    "binaries['separation'] = binaries['separation'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems = systems.reset_index()\n",
    "system_dict = {} \n",
    "\n",
    "for system in range(len(systems)):\n",
    "    system_dict[i] = {}\n",
    "    system_dict[i]['all_children'] = getListOfNames(systems['all_children'][i])\n",
    "    system_dict[i]['child_stars_binaries'] = getListOfNames(systems['child_stars_binaries'][i])\n",
    "    system_dict[i]['index'] = systems['index'][i]\n",
    "    \n",
    "system_dict = pd.DataFrame.from_dict(system_dict)\n",
    "system_dict = system_dict.transpose()\n",
    "systems = systems.drop(['child_stars_binaries', 'all_children'], 1)\n",
    "systems = systems.merge(system_dict, on=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems['distance'] = systems['distance'].str.strip(\" pc\")\n",
    "systems['distance'] = systems['distance'].astype(float)\n",
    "systems = systems.drop(['altnames', 'list', 'epoch'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = systems['right_ascension'] \n",
    "raDict = {}\n",
    "for i in range(len(ra)):\n",
    "    raDict[i] = {}\n",
    "    if type(ra[i]) != str:\n",
    "        raDict[i]['ra_degrees'] = str('nan')\n",
    "        raDict[i]['ra_minutes'] = str('nan')\n",
    "        raDict[i]['ra_seconds'] = str('nan')\n",
    "    else:\n",
    "        tempStr = ra[i]\n",
    "        end = tempStr.find('d')\n",
    "        raDict[i]['ra_degrees'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('m')\n",
    "        raDict[i]['ra_minutes'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('s')\n",
    "        raDict[i]['ra_seconds'] = float(tempStr[:end])\n",
    "ra = None\n",
    "raDict = pd.DataFrame.from_dict(raDict, orient='index', dtype=float)\n",
    "\n",
    "\n",
    "dec = systems['declination']\n",
    "decDict = {}\n",
    "for i in range(len(dec)):\n",
    "    decDict[i] = {}\n",
    "    if type(dec[i]) != str:\n",
    "        decDict[i]['dec_degrees'] = str('nan')\n",
    "        decDict[i]['dec_minutes'] = str('nan')\n",
    "        decDict[i]['dec_seconds'] = str('nan')\n",
    "    else: \n",
    "        tempStr = dec[i]\n",
    "        end = tempStr.find('d')\n",
    "        decDict[i]['dec_degrees'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('m')\n",
    "        decDict[i]['dec_minutes'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('s')\n",
    "        decDict[i]['dec_seconds'] = float(tempStr[:end])\n",
    "dec = None\n",
    "decDict = pd.DataFrame.from_dict(decDict, orient='index', dtype=float)\n",
    "\n",
    "systems = raDict.merge(systems, right_index=True, left_index=True)\n",
    "systems = decDict.merge(systems, right_index=True, left_index=True)\n",
    "systems = systems.drop(['right_ascension', 'declination'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = stars['right_ascension'] \n",
    "raDict = {}\n",
    "for i in range(len(ra)):\n",
    "    raDict[i] = {}\n",
    "    if type(ra[i]) != str:\n",
    "        raDict[i]['ra_degrees'] = str('nan')\n",
    "        raDict[i]['ra_minutes'] = str('nan')\n",
    "        raDict[i]['ra_seconds'] = str('nan')\n",
    "    else:\n",
    "        tempStr = ra[i]\n",
    "        end = tempStr.find('d')\n",
    "        raDict[i]['ra_degrees'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('m')\n",
    "        raDict[i]['ra_minutes'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('s')\n",
    "        raDict[i]['ra_seconds'] = float(tempStr[:end])\n",
    "ra = None\n",
    "raDict = pd.DataFrame.from_dict(raDict, orient='index', dtype=float)\n",
    "\n",
    "\n",
    "dec = stars['declination']\n",
    "decDict = {}\n",
    "for i in range(len(dec)):\n",
    "    decDict[i] = {}\n",
    "    if type(dec[i]) != str:\n",
    "        decDict[i]['dec_degrees'] = str('nan')\n",
    "        decDict[i]['dec_minutes'] = str('nan')\n",
    "        decDict[i]['dec_seconds'] = str('nan')\n",
    "    else:\n",
    "        tempStr = dec[i]\n",
    "        end = tempStr.find('d')\n",
    "        decDict[i]['dec_degrees'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('m')\n",
    "        decDict[i]['dec_minutes'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('s')\n",
    "        decDict[i]['dec_seconds'] = float(tempStr[:end])\n",
    "dec = None\n",
    "decDict = pd.DataFrame.from_dict(decDict, orient='index', dtype=float)\n",
    "\n",
    "child = stars['child_obj']\n",
    "childDict = {}\n",
    "for i in range(len(child)):\n",
    "    childDict[i] = {}\n",
    "    if stars['child_obj'][i] == '':\n",
    "        childDict[i]['children'] = 0\n",
    "    else:\n",
    "        childDict[i]['children'] = float(stars['child_obj'][i].count(',') + 1)\n",
    "child = None\n",
    "childDict = pd.DataFrame.from_dict(childDict, orient='index', dtype=float)\n",
    "\n",
    "num_names = stars['altnames']\n",
    "nameDict = {}\n",
    "for i in range(len(num_names)):\n",
    "    nameDict[i] = {}\n",
    "    if stars['altnames'][i] == '':\n",
    "        nameDict[i]['num_names'] = 1\n",
    "    else:\n",
    "        nameDict[i]['num_names'] = float(stars['altnames'][i].count(',') + 1)\n",
    "num_names = None\n",
    "nameDict = pd.DataFrame.from_dict(nameDict, orient='index', dtype=float)\n",
    "\n",
    "stars = raDict.merge(stars, right_index=True, left_index=True)\n",
    "stars = childDict.merge(stars, right_index=True, left_index=True)\n",
    "stars = decDict.merge(stars, right_index=True, left_index=True)\n",
    "stars = nameDict.merge(stars, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars['altnames'] = stars['altnames'].str.strip('[')\n",
    "stars['altnames'] = stars['altnames'].str.strip(']')\n",
    "stars['all_names'] = stars['proper'] + stars['altnames'].astype(str)\n",
    "stars['all_names'] = \"'\" + stars['all_names']\n",
    "stars['all_names'] = stars['all_names'].str.split(\"'\")\n",
    "stars['all_names'] = stars['altnames'].str.strip('[')\n",
    "stars['all_names'] = stars['altnames'].str.strip(']')\n",
    "stars['all_names'] = stars['all_names'].replace({',', ''})\n",
    "stars['all_names'] = stars['all_names'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = stars.drop(['parent_obj'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIP = stars.loc[stars['hip'] > 0]\n",
    "HD = stars.loc[stars['hd'] > 0]\n",
    "HR = stars.loc[stars['hr'] > 0]\n",
    "GL = stars.loc[stars['gl'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_csv = GL.merge(star_csv, on='gl')\n",
    "HD_csv = HD.merge(star_csv, on='hd')\n",
    "HR_csv = HR.merge(star_csv, on='hr')\n",
    "HIP_csv = HIP.merge(star_csv, on='hip')\n",
    "stars_csv = stars.merge(star_csv, on='proper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIP_csv = HIP_csv.append(GL_csv)\n",
    "HIP_csv = HIP_csv.append(HD_csv)\n",
    "HIP_csv = HIP_csv.append(stars_csv)\n",
    "HIP_csv = HIP_csv.append(HR_csv)\n",
    "HIP_csv['all_names'] = HIP_csv['all_names'].astype(str)\n",
    "HIP_csv = HIP_csv.drop_duplicates('all_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_csv['other_names'] = star_csv['flam'].astype(str).str[:-2].replace('n', '') + ' ' + star_csv['bayer'].astype(str).replace('nan', '') + ' ' + star_csv['con'].astype(str).replace('nan','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_csv['other_names'] = star_csv['other_names'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other_name = star_csv.head(1).add(stars.loc[1])\n",
    "\n",
    "# for i in range(len(stars['all_names'])):\n",
    "#     for j in range(len(stars['all_names'][i])):\n",
    "#         for k in range(len(star_csv['other_names'])): \n",
    "#             if len(star_csv['other_names'][k]) <= 3:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 if str(star_csv['bayer'][k]) in stars['all_names'][i][j]:\n",
    "#                     to_app = pd.concat(objs=[star_csv.loc[k], stars.loc[i]], axis=1)\n",
    "#                     to_app[k] = to_app[k].fillna(to_app[i])\n",
    "#                     to_app = to_app.drop(i, axis=1)\n",
    "#                     to_app = to_app.transpose()\n",
    "#                     other_name = other_name.append(to_app)\n",
    "#                     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other_name.to_csv('vauge_names.csv')\n",
    "other_name = pd.read_csv('vauge_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_name = HIP_csv.append(other_name)\n",
    "other_name = other_name.drop_duplicates(subset='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new estimates roughly 1 in 4 sunlike stars have planets, adjusting for how much data will be lost when dropping null values \n",
    "data = other_name.append(star_csv.sample(2000, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = ['HE', 'NEP', 'CE', 'CN', 'CJ', 'HN', 'HSE', 'JUP', 'SE', 'WJ', 'WN', 'WSE', 'children']\n",
    "for item in list_:\n",
    "    data[item] = data[item].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['children', 'ra', 'dec', 'dist', 'pmra', 'pmdec', 'rv', 'mag', 'absmag', 'spect', 'ci', 'x', 'y', 'z', 'vx', 'vy', 'vz', 'rarad', \n",
    "             'decrad', 'pmrarad', 'pmdecrad','comp_primary', 'lum','HE', 'NEP', 'CE', 'CN', 'CJ', 'HN', 'HSE', 'JUP', 'SE', 'WJ', 'WN', 'WSE']].copy()\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['temp_class'] = data['spect'].str[:1]\n",
    "data['temp_class'] = data['temp_class'].fillna('nan')\n",
    "\n",
    "data['heat_class'] = data['spect'].str[1:2]\n",
    "data['heat_class'] = data['heat_class'].fillna('nan')\n",
    "\n",
    "data['harv_class'] = data['spect'].str[:2]\n",
    "data['harv_class'] = data['harv_class'].fillna('nan')\n",
    "\n",
    "data['lum_class'] = data['spect'].str[2:]\n",
    "data['lum_class'] = data['lum_class'].fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "data = pd.get_dummies(data, columns=['temp_class'], prefix='_y')\n",
    "data = pd.get_dummies(data, columns=['heat_class'], prefix='_x')\n",
    "data = pd.get_dummies(data, columns=['lum_class'], prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['I'] = data['_.5Ia'] + data['_.5Ib'] + data['_/B8Ib'] + data['_Ia'] + data['_Ib'] + data['_Ib/II'] + data['_Ib+...'] + data['_Ib'] \n",
    "data['I'] = data['_Iab:'] + data['I'] + data['_-G2Ie'] + data['_Ia0:'] + data['_Ib-II']\n",
    "\n",
    "data['II'] = data['_Ib/II'] + data['_Ib-II'] + data['_/B9II/III'] + data['_/K0II'] + data['_II'] + data['_II-III'] + data['_II/III'] + data['_IICNp...']\n",
    "data['II'] = data['_IIb'] + data['II']\n",
    "\n",
    "data['III'] = data['_.5III'] + data['_.5III:'] + data['_/A3III'] + data['_/A8III'] + data['_/B8III'] + data['_/B9II/III'] + data['_/B9III/IV'] \n",
    "data['III'] = data['III'] + data['_/G5III'] + data['_/G8III'] + data['_/G8III:'] + data['_/K0III'] + data['_/K0III:'] + data['_/K1III']\n",
    "data['III'] = data['III'] + data['_/K1III+..'] + data['_/K2III'] + data['_/K3III'] + data['_/K3III:'] + data['_/K4III'] + data['_/K4III:'] + data['_/K5III']\n",
    "data['III'] = data['III'] + data['_/M0III'] + data['_/M1III'] + data['_/M2III'] + data['_/M3III'] + data['_:III:'] + data['_III+...'] + data['_II-III']\n",
    "data['III'] = data['III'] + data['_II/IIICNV:'] + data['_III'] + data['_III + (F)'] + data['_III-IV'] + data['_III...'] + data['_III/IV'] + data['_III/IVCN.']\n",
    "data['III'] = data['III'] + data['_III:'] + data['_IIICN...'] + data['_IIICNII'] + data['_IIICNp...'] + data['_IIIb'] + data['_IIIp'] + data['_IIIvar']\n",
    "\n",
    "data['IV'] = data['_.5IV'] + data['_.5IV-V'] + data['_/B9III/IV'] + data['_/A3IV'] + data['_/A3IV/V'] + data['_/A7IV'] + data['_/F2IV'] + data['_/F2IV/V']\n",
    "data['IV'] = data['IV'] + data['_/F3IV'] + data['_/F5IV'] + data['_/F7IV/V'] + data['_/K0IV/V'] + data['_/K1IV'] + data['_/K1IV/V:'] + data['_III-IV']\n",
    "data['IV'] = data['IV'] + data['_III/IV'] + data['_III/IVCN.'] + data['_IV'] + data['_IV-V'] + data['_IV...'] + data['_IV/V'] + data['_IV: (+F/G)']\n",
    "data['IV'] = data['IV'] + data['_IV:pe...'] + data['_IVn'] + data['_IVne+...']\n",
    "\n",
    "data['V'] = data['_ V'] + data['_.5IV-V'] + data['_.5V'] + data['_.5Ve'] + data['_.5Vn'] + data['_/A1V'] + data['_/A2V'] + data['_/A3IV/V']\n",
    "data['V'] = data['V'] + data['_/A3V'] + data['_/A3V+...'] + data['_V+...'] + data['_/B3V'] + data['_/B8V'] + data['_/B9.5V'] + data['_/B9V'] \n",
    "data['V'] = data['V'] + data['_/F2IV/V'] + data['_/F3V'] + data['_/F5V'] + data['_/F6V'] + data['_/F7IV/V'] + data['_/F7V'] + data['_/F8V']\n",
    "data['V'] = data['V'] + data['_/G0V'] + data['_/G1V'] + data['_/G2V'] + data['_/G3V'] + data['_/G5V'] + data['_/G6V'] + data['_/G8V']\n",
    "data['V'] = data['V'] + data['_/K0IV/V'] + data['_/K0V'] + data['_/K1V'] + data['_/K3V'] + data['_/M2V'] + data['_:V...'] + data['_IV-V'] + data['_V']\n",
    "data['V'] = data['V'] + data['_V + G/K'] + data['_V+...'] + data['_V-VI'] + data['_V...'] + data['_V:'] + data['_V:n'] + data['_V:pe'] + data['_VCN...']\n",
    "data['V'] = data['V'] + data['_Ve'] + data['_Ve+...'] + data['_Vn'] + data['_Vne'] + data['_Vp'] + data['_Vw...']\n",
    "\n",
    "data['VI'] = data['_V-VI']\n",
    "\n",
    "data['...'] = data['_+...'] + data['_..'] + data['_...'] + data['_w...'] + data['_sp...'] + data['_V...'] + data['_p...'] + data['_m...']\n",
    "data['...'] = data['...'] + data['_Vw...'] + data['_Ve+...'] + data['_IV:pe...'] + data['_IV...'] + data['_III...'] + data['_:+...']\n",
    "data['...'] = data['...'] + data['_IICNp...'] + data['_III+...'] + data['_/K0p...'] + data['_/G0Vs...'] + data['_Ib+...']\n",
    "data['...'] = data['...'] + data['_:w...'] + data['_:V...'] + data['_:III:+...'] + data['_:+...'] + data['_/K1III+..'] + data['_/G5Vw...'] \n",
    "data['...'] = data['...'] + data['_/A3V+...'] + data['_/G8w...']   + data['_:w...'] + data['_IIICN...'] + data['_IIIp...']\n",
    "data['...'] = data['...'] + data['_IV...'] + data['_IV:pe...'] + data['_IVne+...'] + data['_Ib+...'] + data['_V+...'] + data['_VCN...']\n",
    "\n",
    "data[':'] = data['_.5III:'] + data['_/G8III:'] + data['_/K0III:'] + data['_IV:pe...'] + data['_:+...'] + data['_:III:+...'] + data['_:w...'] + data['_:V...']\n",
    "data[':'] = data[':'] + data['_/K1IV/V:'] + data['_/K3III:'] + data['_/K4III:'] + data['_:'] + data['_II/IIICNV:'] + data['_III:'] + data['_:III:']\n",
    "data[':'] = data[':'] + data['_IV: (+F/G)'] + data['_IV:pe...'] + data['_Ia0:'] + data['_Iab:'] + data['_O:'] + data['_V:'] + data['_V:n'] + data['_V:pe']\n",
    "\n",
    "data['+'] = data['_+...'] + data['_/A3V+...'] + data['_/K0V + A/F'] + data['_Ve+...'] + data['_:III:+...'] + data['_Ib+...']\n",
    "data['+'] = data['+'] + data['_III+...'] + data['_:+...'] + data['_/K1III+..'] + data['_IVne+...'] + data['_Ib+...'] + data['_V + G/K']\n",
    "data['+'] = data['+'] + data['_V+...'] \n",
    "\n",
    "data['A'] = data['_y_A'] + data['_x_A'] + data['_/A1V'] + data['_/A2V'] + data['_/A3III'] + data['_/A3IV'] + data['_/A3IV/V'] + data['_/A3V'] \n",
    "data['A'] = data['A'] + data['_/A7IV'] + data['_/A8III']\n",
    "\n",
    "data['B'] = data['_/B3V'] + data['_/B8III'] + data['_/B8Ib'] + data['_/B8V'] + data['_/B9.5V'] + data['_/B9II/III'] + data['_/B9III/IV']\n",
    "data['B'] = data['B'] + data['_/B9V'] + data['_y_B'] \n",
    "\n",
    "data['C'] = data['_y_C'] + data['_x_C']\n",
    "data['E'] = data['_-G2Ie'] + data['_.5Ve']\n",
    "\n",
    "data['F'] = data['_/F2IV'] + data['_/F2IV/V'] + data['_/F3'] + data['_/F3IV'] + data['_/F3V'] + data['_/F5IV'] + data['_/F5V'] + data['_/F6V'] \n",
    "data['F'] = data['F'] + data['_/F7IV/V'] + data['_/F7V'] + data['_/F8V'] + data['_y_F']\n",
    "\n",
    "data['G'] = data['_y_G'] + data['_-G2Ie'] + data['_/G0V'] + data['_/G1V'] + data['_/G2V'] + data['_/G3V'] + data['_/G5III'] + data['_/G5V']  + data['_/G5Vw...']  \n",
    "data['G'] = data['G'] + data['_/G6V']  + data['_/G8III']  + data['_/G8V']  + data['_/G8w...']  + data['_G2'] \n",
    "\n",
    "data['K'] = data['_y_K'] + data['_x_K'] + data['_/K0II']  + data['_/K0III'] + data['_/K0III:'] + data['_/K0IV/V'] + data['_/K0V'] + data['_/K0V + A/F']\n",
    "data['K'] = data['K'] + data['_/K0p...'] + data['_/K1III'] + data['_/K1III+..'] + data['_/K1IV'] + data['_/K1IV/V:'] + data['_/K1V'] + data['_/K2III']\n",
    "data['K'] = data['K'] + data['_/K3III'] + data['_/K3III:'] + data['_/K3V'] + data['_/K4'] + data['_/K4III'] + data['_/K4III:'] + data['_/K5III'] + data['_y_k']\n",
    "\n",
    "data['N'] = data['_y_N'] + data['_x_N'] \n",
    "data['M'] = data['_y_M'] + data['_x_M'] + data['_/M0III'] + data['_/M1III'] + data['_/M2III'] + data['_/M2V'] + data['_/M3III'] + data['_e-M7e']\n",
    "data['RD'] = data['_y_R'] + data['_x_d']\n",
    "data['S'] = data['_y_s'] + data['_x_s']\n",
    "data['W'] = data['_y_W'] + data['_x_w']\n",
    "data['O'] = data['_y_O'] + data['_/O8'] + data['_O:']\n",
    "\n",
    "data['D'] = data['_y_D']\n",
    "\n",
    "data['n'] = data['_x_n'] + data['_.5Vn'] + data['_IVn'] + data['_IVne+...'] + data['_V:n'] + data['_Vn'] + data['_Vne'] + data['_npe']\n",
    "data['e'] = data['_x_e'] + data['_.5e'] + data['_IV:pe...'] + data['_IVne+...'] + data['_V:pe'] + data['_Ve'] + data['_Ve+...'] + data['_Vne'] + data['_e']\n",
    "data['e'] = data['e'] + data['_e-M7e'] + data['_npe']\n",
    "\n",
    "data['0'] = data['_x_0'] + data['_/G0V'] + data['_/G0Vs...'] + data['_/K0II'] + data['_/K0III'] + data['_/K0III:'] + data['_/K0IV/V'] + data['_/K0V']\n",
    "data['0'] = data['0'] + data['_/K0V + A/F'] + data['_/K0p...'] + data['_/M0III'] + data['_0'] + data['_Ia0:']\n",
    "data['1'] = data['_x_1'] + data['_/A1V'] + data['_/G1V'] + data['_/G2V'] + data['_/K1III'] + data['_/K1III+..'] + data['_/K1IV'] + data['_/K1IV/V:']\n",
    "data['1'] = data['1'] + data['_/K1V'] + data['_/M1III']\n",
    "data['2'] = data['_x_2'] + data['_-G2Ie'] + data['_/A2V'] + data['_/M2III'] + data['_/F2IV'] + data['_/F2IV/V'] + data['_/K2III'] + data['_/M2V'] + data['_G2']\n",
    "data['3'] = data['_x_3'] + data['_/A3III'] + data['_/A3IV'] + data['_/A3IV/V'] + data['_/A3V'] + data['_/A3V+...'] + data['_/B3V'] + data['_/F3']\n",
    "data['3'] = data['3'] + data['_/F3IV'] + data['_/F3V'] + data['_/G2V'] + data['_/K3III'] + data['_/K3III:'] + data['_/K3V'] + data['_/M3III']\n",
    "data['3'] = data['3'] + data['_3'] + data['_3   :']\n",
    "data['4'] = data['_x_4'] + data['_/K4'] + data['_/K4III'] + data['_/K4III:']\n",
    "data['5'] = data['_x_5'] + data['_/F5IV'] + data['_/F5V'] + data['_/G5III'] + data['_/G5V'] + data['_/G5Vw...'] + data['_/K5III'] + data['_5']\n",
    "data['6'] = data['_x_6'] + data['_/F6V'] + data['_/G6V'] + data['_6'] + data['_6 (SB1)'] \n",
    "data['7'] = data['_x_7'] + data['_/A7IV'] + data['_/F7IV/V'] + data['_/F7V'] + data['_7'] + data['_e-M7e']\n",
    "data['8'] = data['_x_8'] + data['_/A8III'] + data['_/B8III'] + data['_/B8Ib'] + data['_/B8V'] + data['_/F8V'] + data['_/G8III'] + data['_/G8III:'] \n",
    "data['8'] = data['_x_8'] + data['_/G8V'] + data['_/G8w...'] + data['_/O8'] + data['_8']\n",
    "data['9'] = data['_x_9'] + data['_/B9.5V'] + data['_/B9II/III'] + data['_/B9III/IV'] + data['_/B9V'] + data['_9'] + data['_9?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(labels=['harv_class', '_y_A', '_y_B', '_y_C', '_y_D', '_y_F', '_y_G', '_y_K', '_y_M', '_y_N', '_y_O',\n",
    "                         '_y_R', '_y_W', '_y_d', '_y_k', '_y_m', '_y_s', '_x_', '_x_-', '_x_.', '_x_0', '_x_1', '_x_2', \n",
    "                         '_x_3', '_x_4', '_x_5', '_x_6', '_x_7', '_x_8', '_x_9', '_x_:', '_x_A', '_x_C', '_x_K', '_x_M', \n",
    "                         '_x_N', '_x_c', '_x_d', '_x_e', '_x_m', '_x_n', '_x_p', '_x_s', '_x_w', '_', '_ Si', '_ V', '_+...', \n",
    "                         '_-G2Ie', '_..', '_...', '_.5', '_.5III', '_.5III:', '_.5IV', '_.5IV-V', '_.5Ia', '_.5Ib', '_.5V', \n",
    "                         '_.5Ve', '_.5Vn', '_.5e', '_/A1V', '_/A2V', '_/A3III', '_/A3IV', '_/A3IV/V', '_/A3V', '_/A3V+...', \n",
    "                         '_/A7IV', '_/A8III', '_/B3V', '_/B8III', '_/B8Ib', '_/B8V', '_/B9.5V', '_/B9II/III', '_/B9III/IV', \n",
    "                         '_/B9V', '_/F2IV', '_/F2IV/V', '_/F3', '_/F3IV', '_/F3V', '_/F5IV', '_/F5V', '_/F6V', '_/F7IV/V',\n",
    "                         '_/F7V', '_/F8V', '_/G0V', '_/G0Vs...', '_/G1V', '_/G2V', '_/G3V', '_/G5III', '_/G5V', '_/G5Vw...', \n",
    "                         '_/G6V', '_/G8III', '_/G8III:', '_/G8V', '_/G8w...', '_/K0II', '_/K0III', '_/K0III:', '_/K0IV/V', '_/K0V',\n",
    "                         '_/K0V + A/F', '_/K0p...', '_/K1III', '_/K1III+..', '_/K1IV', '_/K1IV/V:', '_/K1V', '_/K2III', '_/K3III',\n",
    "                         '_/K3III:', '_/K3V', '_/K4', '_/K4III', '_/K4III:', '_/K5III', '_/M0III', '_/M1III', '_/M2III', '_/M2V',\n",
    "                         '_/M3III', '_/O8', '_0', '_3', '_3   :', '_5', '_6', '_6 (SB1)', '_7', '_8', '_9', '_9?', '_:', '_:+...', \n",
    "                         '_:III:', '_:III:+...', '_:V...', '_:w...', '_G2', '_II', '_II-III', '_II/III', '_II/IIICNV:', '_IICNp...', \n",
    "                         '_III', '_III + (F)', '_III+...', '_III-IV', '_III...', '_III/IV', '_III/IVCN.', '_III:', '_IIICN...', '_IIICNII',\n",
    "                         '_IIICNp...', '_IIIb', '_IIIp', '_IIIp...', '_IIIvar', '_IIb', '_IV', '_IV-V', '_IV...', '_IV/V', '_IV: (+F/G)',\n",
    "                         '_IV:pe...', '_IVn', '_IVne+...', '_Ia', '_Ia0:', '_Iab:', '_Ib', '_Ib+...', '_Ib-II', '_Ib/II', '_O:', '_Sv', \n",
    "                         '_V', '_V + G/K', '_V+...', '_V-VI', '_V...', '_V:', '_V:n', '_V:pe', '_VCN...', '_Ve', '_Ve+...', '_Vn', '_Vne', \n",
    "                         '_Vp', '_Vs', '_Vw...', '_e', '_e-M7e', '_m', '_m...', '_npe', '_p', '_p...', '_psh', '_sp...', '_w...', '_wp', 'spect',\n",
    "                         'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ra'] = data['ra'].astype(float)\n",
    "data['dec'] = data['dec'].astype(float)\n",
    "data['dist'] = data['dist'].astype(float)\n",
    "data['pmra'] = data['pmra'].astype(float)\n",
    "data['pmdec'] = data['pmdec'].astype(float)\n",
    "data['rv'] = data['rv'].astype(float)\n",
    "data['mag'] = data['mag'].astype(float)\n",
    "data['absmag'] = data['absmag'].astype(float)\n",
    "data['x'] = data['x'].astype(float)\n",
    "data['y'] = data['y'].astype(float)\n",
    "data['z'] = data['z'].astype(float)\n",
    "data['vx'] = data['vx'].astype(float)\n",
    "data['vz'] = data['vz'].astype(float)\n",
    "data['vy'] = data['vy'].astype(float)\n",
    "data['rarad'] = data['rarad'].astype(float)\n",
    "data['decrad'] = data['decrad'].astype(float)\n",
    "data['pmrarad'] = data['pmrarad'].astype(float)\n",
    "data['pmdecrad'] = data['pmdecrad'].astype(float)\n",
    "data['comp_primary'] = data['comp_primary'].astype(float)\n",
    "data['lum'] = data['lum'].astype(float)\n",
    "data['ci'] = data['ci'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('scrubbed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
