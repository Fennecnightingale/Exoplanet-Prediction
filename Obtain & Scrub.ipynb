{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import exodata\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import exodata.astroquantities as aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(x):\n",
    "    \"\"\"pass in a value you'd like to check to see if it is not a number, not to be confused with .isna() which returns checks if null\"\"\"\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToString(s):  \n",
    "    \"\"\"pass in list, returns string\"\"\"\n",
    "    str1 = \",\" \n",
    "    return (str1.join(s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfNames(names):\n",
    "    \"\"\"Pass in a string from dataframe that has names surrounded by parentheses you'd like to extract the names from\n",
    "    ex: stars['name'] = Star('11 com b') -> stars['name'] = '11 com b'\"\"\"\n",
    "    temp = \"\"\n",
    "    while len(names) > 2:\n",
    "        start = names.find('(') + 2\n",
    "        end = names.find(')') - 1\n",
    "        temp += names[start:end] if len(temp) == 0 else \", \" + names[start:end]\n",
    "        names = names[end + 2 :]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findGLName(primary, alts):\n",
    "    \"\"\"extract Gliese name & ID number and arrange them in formatting that matches current standard stellar naming conventions\n",
    "    ex: stars['altnames'] = ['11 com b', 'Gliese 234', 'HD137'] -> stars['GL'] = 'GL 234'\"\"\"\n",
    "    prefixes = [\"GL \", \"Gliese \", \"NN \", \"WO \", \"GJ \"]\n",
    "    name = \"\"\n",
    "    for i in range(len(prefixes)):\n",
    "        if primary.startswith(prefixes[i]):\n",
    "            name = primary\n",
    "            break\n",
    "    if name == \"\" and alts != \"\":\n",
    "        for i in range(len(alts)):\n",
    "            for j in range(len(prefixes)):\n",
    "                if alts[i].startswith(prefixes[j]):\n",
    "                    name = alts[i]\n",
    "                    break\n",
    "            if name != \"\":\n",
    "                break\n",
    "    if name == \"\":\n",
    "        return np.nan\n",
    "    if name.startswith(\"GL\"):\n",
    "        name = \"Gl\" + name[2:]\n",
    "    elif name.startswith(\"WO\"):\n",
    "        name = \"Wo\" + name[2:]\n",
    "    elif name.startswith(\"Gliese\"):\n",
    "        name = \"GJ\" + name[6:]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOtherName(check, primary, alts):\n",
    "    \"\"\"extract other names & ID number and arrange them in formatting that matches current standard stellar naming conventions\n",
    "    ex: stars['altnames'] = ['11 com b', 'Gliese 234', 'HD137'] -> stars['HD'] = '137'\"\"\"\n",
    "    name = \"\"\n",
    "    if primary.startswith(check):\n",
    "        name = primary[len(check) + 1:]\n",
    "    if name == \"\" and alts == \"\":\n",
    "        return np.nan\n",
    "    for i in range(len(alts)):\n",
    "        if alts[i].startswith(check):\n",
    "            name = alts[i][len(check) + 1:]\n",
    "    if name == \"\":\n",
    "        return np.nan\n",
    "    while re.search(\"\\D\", name):\n",
    "        name = name[:-1]\n",
    "    return float(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: IllegalSecondWarning: 'second' was found  to be '60', which is not in range [0,60). Treating as 0 sec, +1 min [astropy.coordinates.angle_utilities]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Jupiter\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Jupiter\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Jupiter\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Saturn\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Saturn\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Saturn\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Saturn\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Saturn\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Uranus\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Uranus\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Uranus\n",
      "rejected duplicate satellite: \n",
      "\t\t\t\t in Uranus\n"
     ]
    }
   ],
   "source": [
    "# load the most current data from the Open Exoplanet Catalouge from db url for most up to date & add csv with more stars that do not have planets \n",
    "exocat = exodata.load_db_from_url('https://github.com/OpenExoplanetCatalogue/oec_gzip/raw/master/systems.xml.gz')\n",
    "star_csv = pd.read_csv('hygdata_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign names to tree branches we'll be using \n",
    "planets = exocat.planets\n",
    "systems = exocat.systems\n",
    "stars = exocat.stars\n",
    "binary = exocat.binaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove every bit of info from the xml and transfer it to a dataframe, first we'll be making each of the branches into it's own dictionary \n",
    "sys_dict = {}\n",
    "bn_dict = {}\n",
    "star_dict = {}\n",
    "pln_dict = {}\n",
    "\n",
    "#then we iterate over each element in the branch and fill the dictionaries with the information they contain, data is stored in this tree\n",
    "#in both callable methods, and within a dictionary within one of those methods, which makes it kind of a mess to extract \n",
    "#also the module is written to raise errors instead of returning nothing, so everything has to be wrapped in a try statement with nan being fill if not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try these with continue instead of the except statement and see what if anything changes, might be able to shorten \n",
    "# also change to i in range \n",
    "i = 0 \n",
    "while i < 3307:\n",
    "    sys_dict[i] = {}\n",
    "    try:\n",
    "        sys_dict[i]['right_ascension'] = systems[i].ra\n",
    "    except:\n",
    "        sys_dict[i]['right_ascension'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['altnames'] = systems[i].altnames\n",
    "    except:\n",
    "        sys_dict[i]['altnames'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['list'] = systems[i].list\n",
    "    except:\n",
    "        sys_dict[i]['list'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['declination'] = systems[i].dec\n",
    "    except:\n",
    "        sys_dict[i]['declination'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['distance'] = systems[i].d\n",
    "    except:\n",
    "        sys_dict[i]['distance'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['child_stars_binaries'] = getListOfNames(str(systems[i].stars))\n",
    "    except:\n",
    "        sys_dict[i]['child_stars_binaries'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['epoch'] = systems[i].epoch\n",
    "    except:\n",
    "        sys_dict[i]['epoch'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['name'] = systems[i].name\n",
    "    except:\n",
    "        sys_dict[i]['name'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['all_children'] = getListOfNames(str(systems[i].children))\n",
    "    except:\n",
    "        sys_dict[i]['all_children'] = np.nan\n",
    "    try:\n",
    "        sys_dict[i]['flags'] = systems[i].flags\n",
    "    except:\n",
    "        sys_dict[i]['flags'] = np.nan\n",
    "    i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try these with continue instead of the except statement and see what if anything changes, might be able to shorten \n",
    "# also change to i in range \n",
    "i = 0 \n",
    "while i < 202:\n",
    "    bn_dict[i] = {}\n",
    "    bn_dict[i]['flags'] = binary[i].flags\n",
    "    bn_dict[i]['system'] = binary[i].system\n",
    "    try:\n",
    "        bn_dict[i]['names'] = binary[i].params['name']\n",
    "    except:\n",
    "        bn_dict[i]['names'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['separation'] = binary[i].params['separation']\n",
    "    except:\n",
    "        bn_dict[i]['separation'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['position_angle'] = binary[i].params['positionangle']\n",
    "    except:\n",
    "        bn_dict[i]['position_angle'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['distance'] = binary[i].d\n",
    "    except:\n",
    "        bn_dict[i]['distance'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['periastron'] = binary[i].periastron\n",
    "    except:\n",
    "        bn_dict[i]['periastron'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['inclination'] = binary[i].i\n",
    "    except:\n",
    "        bn_dict[i]['inclination'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['parent_obj'] = binary[i].parent\n",
    "    except: \n",
    "        bn_dict[i]['parent_obj'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['child_obj'] = binary[i].children\n",
    "    except: \n",
    "        bn_dict[i]['child_obj'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['stars'] = binary[i].stars\n",
    "    except: \n",
    "        bn_dict[i]['stars'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['period'] = binary[i].P\n",
    "    except: \n",
    "        bn_dict[i]['period'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['semi_major_axis'] = binary[i].a\n",
    "    except: \n",
    "        bn_dict[i]['semi_major_axis'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['eccentricity'] = binary[i].e\n",
    "    except: \n",
    "        bn_dict[i]['eccentricity'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['longitude'] = binary[i].longitude\n",
    "    except: \n",
    "        bn_dict[i]['longitude'] = np.nan\n",
    "    try:\n",
    "        bn_dict[i]['ascending_node'] = binary[i].ascendingnode\n",
    "    except: \n",
    "        bn_dict[i]['ascending_node'] = np.nan\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\learn-env\\lib\\site-packages\\quantities\\quantity.py:424: RuntimeWarning: invalid value encountered in greater\n",
      "  return self.magnitude > other\n",
      "C:\\ProgramData\\anaconda3\\envs\\learn-env\\lib\\site-packages\\quantities\\quantity.py:391: RuntimeWarning: invalid value encountered in less\n",
      "  return self.magnitude < other\n"
     ]
    }
   ],
   "source": [
    "# try these with continue instead of the except statement and see what if anything changes, might be able to shorten \n",
    "# also change to i in range \n",
    "i = 0 \n",
    "while i < 3505:\n",
    "    star_dict[i] = {}\n",
    "    try:\n",
    "        star_dict[i]['spectral_type'] = stars[i].params['spectraltype']\n",
    "    except: \n",
    "        star_dict[i]['spectral_type'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['temp'] = stars[i].params['temperature']\n",
    "    except:\n",
    "        star_dict[i]['temp'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['metallicity'] = stars[i].params['metallicity']\n",
    "    except:\n",
    "        star_dict[i]['metallicity'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['altnamesstr'] = listToString(stars[i].params['altnames'])\n",
    "    except:\n",
    "        star_dict[i]['altnames'] = ''\n",
    "    try:\n",
    "        star_dict[i]['altnames'] = stars[i].params['altnames']\n",
    "    except:\n",
    "        star_dict[i]['altnames'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['mass'] = stars[i].params['mass']\n",
    "    except:\n",
    "        star_dict[i]['mass'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magUltraviolet'] = stars[i].params['magU']\n",
    "    except:\n",
    "        star_dict[i]['magUltraviolet'] = np.nan\n",
    "    try: \n",
    "        star_dict[i]['magBlue'] = stars[i].params['magB']\n",
    "    except:\n",
    "        star_dict[i]['magBlue'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magH_nearinfared'] = stars[i].params['magH']\n",
    "    except:\n",
    "        star_dict[i]['magH_nearinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magInfared'] = stars[i].params['magI']\n",
    "    except: \n",
    "        star_dict[i]['magInfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magJ_nearinfared'] = stars[i].params['magJ']\n",
    "    except: \n",
    "        star_dict[i]['magJ_nearinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magK_nearinfared'] = stars[i].params['magK']\n",
    "    except: \n",
    "        star_dict[i]['magK_nearinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magVisual'] = stars[i].params['magV']\n",
    "    except: \n",
    "        star_dict[i]['magVisual'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magL_nq_midinfared'] = stars[i].params['magL']\n",
    "    except:\n",
    "        star_dict[i]['magL_nq_midinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magM_midinfared'] = stars[i].params['magM']\n",
    "    except: \n",
    "        star_dict[i]['magM_midinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['magN_midinfared'] = stars[i].params['magN']\n",
    "    except:\n",
    "        star_dict[i]['magN_midinfared'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['distance'] = stars[i].d\n",
    "    except:\n",
    "        star_dict[i]['distance'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['periastron'] = stars[i].params['periastron']\n",
    "    except:\n",
    "        star_dict[i]['periastron'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['right_ascension'] = stars[i].ra\n",
    "    except:\n",
    "        star_dict[i]['right_ascension'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['declination'] = stars[i].dec\n",
    "    except:\n",
    "        star_dict[i]['declination'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['parent_obj'] = getListOfNames(str(stars[i].parent))\n",
    "    except: \n",
    "        star_dict[i]['parent_obj'] = np.nan\n",
    "    try:\n",
    "        star_dict[i]['child_obj'] = getListOfNames(str(stars[i].children))\n",
    "    except: \n",
    "        star_dict[i]['child_obj'] = np.nan\n",
    "    try: \n",
    "        star_dict[i]['planet1type'] = stars[i].children[0].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet1type'] = np.nan  \n",
    "    try: \n",
    "        star_dict[i]['planet2type'] = stars[i].children[1].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet2type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet3type'] = stars[i].children[2].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet3type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet4type'] = stars[i].children[3].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet4type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet5type'] = stars[i].children[4].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet5type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet6type'] = stars[i].children[5].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet6type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet7type'] = stars[i].children[6].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet7type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet8type'] = stars[i].children[7].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet8type'] = np.nan \n",
    "    try: \n",
    "        star_dict[i]['planet9type'] = stars[i].children[8].type()   \n",
    "    except: \n",
    "        star_dict[i]['planet9type'] = np.nan \n",
    "    star_dict[i]['proper'] = stars[i].name\n",
    "    star_dict[i]['flags'] = stars[i].flags\n",
    "    star_dict[i]['system'] = getListOfNames(str(stars[i].system))\n",
    "    star_dict[i]['radius'] = stars[i].R\n",
    "    star_dict[i]['age'] = stars[i].age\n",
    "    star_dict[i]['hip'] = findOtherName(\"HIP \", star_dict[i]['proper'], star_dict[i]['altnames'])\n",
    "    star_dict[i]['hd'] = findOtherName(\"HD \", star_dict[i]['proper'], star_dict[i]['altnames'])\n",
    "    star_dict[i]['hr'] = findOtherName(\"HR \", star_dict[i]['proper'], star_dict[i]['altnames'])\n",
    "    star_dict[i]['gl'] = findGLName(star_dict[i]['proper'], star_dict[i]['altnames'])\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try these with continue instead of the except statement and see what if anything changes, might be able to shorten \n",
    "# also change to i in range \n",
    "i = 0\n",
    "while i < 4499:\n",
    "    pln_dict[i] = {}\n",
    "    pln_dict[i]['flags'] = planets[i].flags\n",
    "    pln_dict[i]['radius'] = planets[i].R\n",
    "    pln_dict[i]['orbital_inclination'] = planets[i].i\n",
    "    pln_dict[i]['seperation'] = planets[i].seperation\n",
    "    pln_dict[i]['age'] = planets[i].age\n",
    "    pln_dict[i]['transit_time'] = planets[i].transittime\n",
    "    pln_dict[i]['longitude'] = planets[i].longitude\n",
    "    pln_dict[i]['ascending_node'] = planets[i].ascendingnode\n",
    "    pln_dict[i]['discovery_method'] = planets[i].discoveryMethod\n",
    "    pln_dict[i]['discovery_year'] = planets[i].discoveryYear\n",
    "    pln_dict[i]['description '] = planets[i].description\n",
    "    pln_dict[i]['alt_names'] = planets[i].params['altnames']\n",
    "    pln_dict[i]['list'] = planets[i].params['list']\n",
    "    try:\n",
    "        pln_dict[i]['system'] = getListOfNames(str(planets[i].system))\n",
    "    except:\n",
    "        pln_dict[i]['system'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['name'] = planets[i].name\n",
    "    except:\n",
    "        pln_dict[i]['name'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['type'] = planets[i].type()\n",
    "    except:\n",
    "        pln_dict[i]['type'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['mass'] = planets[i].params['mass']\n",
    "    except:\n",
    "        pln_dict[i]['mass'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['semi_major_axis'] = planets[i].params['semimajoraxis']\n",
    "    except:\n",
    "        pln_dict[i]['semi_major_axis'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['orbital_period'] = planets[i].params['period']\n",
    "    except:\n",
    "        pln_dict[i]['orbital_period'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['periastron'] = planets[i].params['periastron']\n",
    "    except:\n",
    "        pln_dict[i]['orbital_period'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['periastron_time'] = planets[i].params['periastrontime']\n",
    "    except:\n",
    "        pln_dict[i]['periastron_time'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['eccentricity'] = planets[i].params['eccentricity']\n",
    "    except:\n",
    "        pln_dict[i]['eccentricity'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['distance'] = planets[i].d\n",
    "    except:\n",
    "        pln_dict[i]['distance'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['periastron'] = planets[i].params['periastron']\n",
    "    except:\n",
    "        pln_dict[i]['periastron'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['temp'] = planets[i].T\n",
    "    except:\n",
    "        pln_dict[i]['temp'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['right_ascension'] = planets[i].ra\n",
    "    except:\n",
    "        pln_dict[i]['right_ascension'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['declination'] = planets[i].dec\n",
    "    except:\n",
    "        pln_dict[i]['declination'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['parent_obj'] = getListOfNames(str(planets[i].parent))\n",
    "    except: \n",
    "        pln_dict[i]['parent_obj'] = np.nan\n",
    "    try:\n",
    "        pln_dict[i]['star'] = getListOfNames(str(planets[i].star))\n",
    "    except: \n",
    "        pln_dict[i]['star'] = np.nan\n",
    "    i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all of my dictionaries to dataframes so I can work with them in pandas \n",
    "pdf = pd.DataFrame(pln_dict)\n",
    "sdf = pd.DataFrame(star_dict)\n",
    "bdf = pd.DataFrame(bn_dict)\n",
    "sysdf = pd.DataFrame(sys_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realign them so my columns are on top and rows go downward \n",
    "planets = pdf.transpose()\n",
    "stars = sdf.transpose()\n",
    "systems = sysdf.transpose()\n",
    "binaries = bdf.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly check over data and drop columns that are already noticably unusable \n",
    "planets = planets.drop(labels=['age','seperation','longitude','ascending_node','periastron_time', 'discovery_year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to get name here? \n",
    "# clean up planets to correctly cast columns to dtypes\n",
    "planets['radius'] = planets['radius'].str.strip(to_strip=\" R_j\")\n",
    "planets['orbital_inclination'] = planets['orbital_inclination'].str.strip(to_strip=\" deg\")\n",
    "planets['transit_time'] = planets['transit_time'].str.strip(to_strip=\" JD\")\n",
    "planets['mass'] = planets['mass'].str.strip(\" M_j\")\n",
    "planets['semi_major_axis'] = planets['semi_major_axis'].str.strip(\" au\")\n",
    "planets['orbital_period'] = planets['orbital_period'].str.strip(\" d\")\n",
    "planets['periastron'] = planets['periastron'].str.strip(\" deg\")\n",
    "planets['distance'] = planets['distance'].str.strip(\" pc\")\n",
    "planets['temp'] = planets['temp'].str.strip(\" K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all columns to correct dtypes \n",
    "planets['radius'] = planets['radius'].astype(float)\n",
    "planets['orbital_period'] = planets['orbital_period'].astype(float)\n",
    "planets['mass'] = planets['mass'].astype(float)\n",
    "planets['transit_time'] = planets['transit_time'].astype(float)\n",
    "planets['orbital_inclination'] = planets['orbital_inclination'].astype(float)\n",
    "planets['periastron'] = planets['periastron'].astype(float)\n",
    "planets['distance'] = planets['distance'].astype(float)\n",
    "planets['temp'] = planets['temp'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what was I doing here?\n",
    "# did this work?\n",
    "i = 0\n",
    "letter = []\n",
    "for i in range(0, 4499):\n",
    "    letter.append(planets['name'][i][-1:])\n",
    "planets['letter'] = letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and rename planets to be consistent to that you don't end up with 600 dummy variables where you only need 6 \n",
    "planets['letter'].replace(to_replace={'A': 'B', 'a':'B', '1':'B','2':'C', '3':'D', '4':'E', '8':'I'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix individual indices with wonky planet letters\n",
    "planets.iloc[3766] = planets.iloc[3766].replace({'n': 'b'})\n",
    "planets.iloc[4178] = planets.iloc[4178].replace({'o': 'h'})\n",
    "planets.iloc[1669] = planets.iloc[1669].replace({'X': 'd'})\n",
    "planets.iloc[4174] = planets.iloc[4174].replace({'r': 'j'})\n",
    "planets.iloc[4170] = planets.iloc[4170].replace({'y': 'b'})\n",
    "planets.iloc[4175] = planets.iloc[4175].replace({'n': 'f'})\n",
    "planets.iloc[4171] = planets.iloc[4171].replace({'s': 'b'})\n",
    "planets.iloc[4173] = planets.iloc[4173].replace({'s': 'd'})\n",
    "planets.iloc[4176] = planets.iloc[4176].replace({'s': 'f'})\n",
    "planets.iloc[3754] = planets.iloc[3754].replace({'s': 'c'})\n",
    "planets['letter'] = planets['letter'].astype(str)\n",
    "planets['letter'] = planets['letter'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummy variables of other applicable columns \n",
    "planets['confirmed_planet'] = planets['list'].str.contains('Confirmed planets')\n",
    "planets['retracted'] = planets['list'].str.contains('Retracted planet candidate')\n",
    "planets['binary_system'] = planets['list'].str.contains('binary systems')\n",
    "planets = planets.drop('list', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(planets['discovery_method'], drop_first=True)\n",
    "planets = planets.merge(dummies, left_index=True, right_index=True)\n",
    "planets = planets.drop('discovery_method', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change your bools to ints so they're no longer objects \n",
    "planets = planets.replace({True: 1, False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up stars to correctly cast to dtypes \n",
    "stars['radius'] = stars['radius'].str.strip(to_strip=\" R_s\")\n",
    "stars['age'] = stars['age'].str.strip(\" Gyr\")\n",
    "stars['mass'] = stars['mass'].str.strip(\" M_s\")\n",
    "stars['distance'] = stars['distance'].str.strip(\" pc\")\n",
    "stars['temp'] = stars['temp'].str.strip(\" K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with little to no information\n",
    "stars = stars.drop(['magL_nq_midinfared', 'magM_midinfared', 'magN_midinfared', 'periastron'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recast everything as dtypes we can work with \n",
    "stars['radius'] = stars['radius'].astype(float) \n",
    "stars['age'] = stars['age'].astype(float) \n",
    "stars['temp'] = stars['temp'].astype(float) \n",
    "stars['mass'] = stars['mass'].astype(float) \n",
    "stars['distance'] = stars['distance'].astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe turn this into a loop to do it? any way to clean it up \n",
    "# I want to know how many total of each variety of planet each star has, to see if we can predict which type a star with a planet will have based on \n",
    "# its features. I have a maximum of 8 planets in any solar system (excluding pluto which is still on the list as a dwarf)\n",
    "columns = {'Cold Jupiter':'CJ', 'Cold Neptune':'CN', 'Cold Super-Earth':'CE', 'Hot Jupiter':'HE', \n",
    "           'Hot Neptune':'HN', 'Hot Super-Earth':'HSE', 'None Jupiter':'JUP', 'None Neptune':'NEP', \n",
    "           'None Super-Earth':'SE', 'Warm Jupiter':'WJ', 'Warm Neptune':'WN', 'Warm Super-Earth':'WSE'}\n",
    "\n",
    "dumms1 = pd.get_dummies(stars['planet1type'])\n",
    "dumms1 = dumms1.rename(columns=columns)\n",
    "dumms2 = pd.get_dummies(stars['planet2type'])\n",
    "dumms2 = dumms2.rename(columns=columns)\n",
    "dumms3 = pd.get_dummies(stars['planet3type'])\n",
    "dumms3 = dumms3.rename(columns=columns)\n",
    "dumms4 = pd.get_dummies(stars['planet4type'])\n",
    "dumms4 = dumms4.rename(columns=columns)\n",
    "dumms5 = pd.get_dummies(stars['planet5type'])\n",
    "dumms5 = dumms5.rename(columns=columns)\n",
    "dumms6 = pd.get_dummies(stars['planet6type'])\n",
    "dumms6 = dumms6.rename(columns=columns)\n",
    "dumms7 = pd.get_dummies(stars['planet7type'])\n",
    "dumms7 = dumms7.rename(columns=columns)\n",
    "dumms8 = pd.get_dummies(stars['planet8type'])\n",
    "dumms8 = dumms8.rename(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = dumms1.merge(dumms2, left_index=True, right_index=True, suffixes=('1', '2'))\n",
    "d2 = d1.merge(dumms3, left_index=True, right_index=True)\n",
    "d3 = d2.merge(dumms4, left_index=True, right_index=True, suffixes=('3', '4'))\n",
    "d4 = d3.merge(dumms5, left_index=True, right_index=True)\n",
    "d5 = d4.merge(dumms6, left_index=True, right_index=True, suffixes=('6', '6'))\n",
    "d6 = d5.merge(dumms7, left_index=True, right_index=True)\n",
    "pln_types = d6.merge(dumms8, left_index=True, right_index=True, suffixes=('7', '8'))\n",
    "pln_types = pln_types.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_types['CJ'] = pln_types['CJ1'] + pln_types['CJ2'] + pln_types['CJ3'] + pln_types['CJ4'] + pln_types['CJ7'] + pln_types['CJ8'] \n",
    "pln_types['CN'] = pln_types['CN1'] + pln_types['CN2'] + pln_types['CN3'] + pln_types['CN4'] + pln_types['CN_x'] + pln_types['CN_y'] + pln_types['CN'] \n",
    "pln_types['CE'] = pln_types['CE1'] + pln_types['CE2'] + pln_types['CE3'] + pln_types['CE4'] + pln_types['CE'] \n",
    "pln_types['HE'] = pln_types['HE'] \n",
    "pln_types['HN'] = pln_types['HN1'] + pln_types['HN2'] \n",
    "pln_types['HSE'] = pln_types['HSE1'] + pln_types['HSE2'] + pln_types['HSE3'] \n",
    "pln_types['JUP'] = pln_types['JUP1'] + pln_types['JUP2'] + pln_types['JUP3']\n",
    "pln_types['NEP'] = pln_types['NEP1'] + pln_types['NEP2'] + pln_types['NEP']\n",
    "pln_types['SE'] = pln_types['SE1'] + pln_types['SE2'] + pln_types['SE3'] + pln_types['SE4']\n",
    "pln_types['WJ'] = pln_types['WJ1'] + pln_types['WJ2'] + pln_types['WJ3'] + pln_types['WJ4'] \n",
    "pln_types['WN'] = pln_types['WN1'] + pln_types['WN2'] + pln_types['WN3'] + pln_types['WN4']\n",
    "pln_types['WSE'] = pln_types['WSE1'] + pln_types['WSE2'] + pln_types['WSE3'] + pln_types['WSE4'] + pln_types['WSE7'] + pln_types['WSE8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pln_types = pln_types.drop(columns=['CJ1', 'CN1', 'CE1', 'HN1', 'HSE1', 'JUP1', 'NEP1', 'SE1', 'WJ1', 'WN1', 'WSE1',\n",
    "                     'CJ2', 'CN2', 'CE2', 'HN2', 'HSE2', 'JUP2', 'NEP2', 'SE2', 'WJ2', 'WN2', 'WSE2', 'CJ3', \n",
    "                     'CN3', 'CE3', 'HSE3', 'JUP3', 'SE3', 'WJ3', 'WN3', 'WSE3', 'CJ4', 'CN4', 'CE4', \n",
    "                     'HSE4', 'JUP4', 'SE4', 'WJ4', 'WN4', 'WSE4', 'CJ6', 'CN_x', 'CE6', 'SE6', 'WSE6', 'CJ6',\n",
    "                     'CE6', 'SE6', 'WSE6', 'CJ7', 'CN_y', 'WSE7', 'CJ8', 'WSE8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = stars.merge(pln_types, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaries['separation'] = binaries['separation'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaries['distance'] = binaries['distance'].str.strip(\" pc\")\n",
    "binaries['distance'] = binaries['distance'].astype(float)\n",
    "binaries['separation'] = binaries['separation'].str.strip(\" au\")\n",
    "binaries['separation'] = binaries['separation'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "systems['distance'] = systems['distance'].str.strip(\" pc\")\n",
    "systems['distance'] = systems['distance'].astype(float)\n",
    "systems = systems.drop(['altnames', 'list', 'epoch'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = systems['right_ascension'] \n",
    "raDict = {}\n",
    "for i in range(len(ra)):\n",
    "    raDict[i] = {}\n",
    "    if type(ra[i]) != str:\n",
    "        raDict[i]['ra_degrees'] = str('nan')\n",
    "        raDict[i]['ra_minutes'] = str('nan')\n",
    "        raDict[i]['ra_seconds'] = str('nan')\n",
    "    else:\n",
    "        tempStr = ra[i]\n",
    "        end = tempStr.find('d')\n",
    "        raDict[i]['ra_degrees'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('m')\n",
    "        raDict[i]['ra_minutes'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('s')\n",
    "        raDict[i]['ra_seconds'] = float(tempStr[:end])\n",
    "ra = None\n",
    "raDict = pd.DataFrame.from_dict(raDict, orient='index', dtype=float)\n",
    "\n",
    "\n",
    "dec = systems['declination']\n",
    "decDict = {}\n",
    "for i in range(len(dec)):\n",
    "    decDict[i] = {}\n",
    "    if type(dec[i]) != str:\n",
    "        decDict[i]['dec_degrees'] = str('nan')\n",
    "        decDict[i]['dec_minutes'] = str('nan')\n",
    "        decDict[i]['dec_seconds'] = str('nan')\n",
    "    else: \n",
    "        tempStr = dec[i]\n",
    "        end = tempStr.find('d')\n",
    "        decDict[i]['dec_degrees'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('m')\n",
    "        decDict[i]['dec_minutes'] = float(tempStr[:end])\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('s')\n",
    "        decDict[i]['dec_seconds'] = float(tempStr[:end])\n",
    "dec = None\n",
    "decDict = pd.DataFrame.from_dict(decDict, orient='index', dtype=float)\n",
    "\n",
    "systems = raDict.merge(systems, right_index=True, left_index=True)\n",
    "systems = decDict.merge(systems, right_index=True, left_index=True)\n",
    "systems = systems.drop(['right_ascension', 'declination'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra = stars['right_ascension']\n",
    "raDict = {}\n",
    "for i in range(len(ra)):\n",
    "    raDict[i] = {}\n",
    "    if ra[i] == np.nan:\n",
    "        raDict[i]['ra_degrees'] = np.nan\n",
    "        raDict[i]['ra_minutes'] = np.nan\n",
    "        raDict[i]['ra_seconds'] = np.nan\n",
    "    else:\n",
    "        tempStr = str(ra[i])\n",
    "        end = tempStr.find('d')\n",
    "        raDict[i]['ra_degrees'] = tempStr[:end]\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('m')\n",
    "        raDict[i]['ra_minutes'] = tempStr[:end]\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('s')\n",
    "        raDict[i]['ra_seconds'] = tempStr[:end]\n",
    "raDict = pd.DataFrame.from_dict(raDict, orient='index', dtype=float)\n",
    "\n",
    "\n",
    "dec = stars['declination']\n",
    "\n",
    "decDict = {}\n",
    "for i in range(len(dec)):\n",
    "    decDict[i] = {}\n",
    "    if dec[i] == np.nan:\n",
    "        decDict[i]['dec_degrees'] = np.nan\n",
    "        decDict[i]['dec_minutes'] = np.nan\n",
    "        decDict[i]['dec_seconds'] = np.nan\n",
    "    else:\n",
    "        tempStr = str(dec[i])\n",
    "        end = tempStr.find('d')\n",
    "        decDict[i]['dec_degrees'] = tempStr[:end]\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('m')\n",
    "        decDict[i]['dec_minutes'] = tempStr[:end]\n",
    "        tempStr = tempStr[end + 1 :]\n",
    "        end = tempStr.find('s')\n",
    "        decDict[i]['dec_seconds'] = tempStr[:end]\n",
    "decDict = pd.DataFrame.from_dict(decDict, orient='index', dtype=float)\n",
    "\n",
    "child = stars['child_obj'].astype(str)\n",
    "childDict = {}\n",
    "for i in range(len(child)):\n",
    "    childDict[i] = {}\n",
    "    if child[i] == '':\n",
    "        childDict[i]['children'] = 0.0\n",
    "    else:\n",
    "        childDict[i]['children'] = float(child[i].count(',') + 1.0)\n",
    "childDict = pd.DataFrame.from_dict(childDict, orient='index', dtype=float)\n",
    "\n",
    "num_names = stars['altnamesstr'].astype(str)\n",
    "nameDict = {}\n",
    "for i in range(len(num_names)):\n",
    "    nameDict[i] = {}\n",
    "    if num_names[i] == '':\n",
    "        nameDict[i]['num_names'] = 1.0\n",
    "    else:\n",
    "        nameDict[i]['num_names'] = float(num_names[i].count(',') + 2.0)\n",
    "nameDict = pd.DataFrame.from_dict(nameDict, orient='index', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars = raDict.merge(stars, right_index=True, left_index=True)\n",
    "stars = childDict.merge(stars, right_index=True, left_index=True)\n",
    "stars = decDict.merge(stars, right_index=True, left_index=True)\n",
    "stars = nameDict.merge(stars, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars['all_names'] = stars['proper'] + ',' + stars['altnamesstr']\n",
    "stars['all_names'] = stars['all_names'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIP = stars.loc[stars['hip'] > 0]\n",
    "HD = stars.loc[stars['hd'] > 0]\n",
    "HR = stars.loc[stars['hr'] > 0]\n",
    "GL = stars.loc[stars['gl'].notnull()]\n",
    "proper = star_csv.loc[star_csv['proper'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "GL_csv = GL.merge(star_csv, on='gl')\n",
    "HD_csv = HD.merge(star_csv, on='hd')\n",
    "HR_csv = HR.merge(star_csv, on='hr')\n",
    "HIP_csv = HIP.merge(star_csv, on='hip')\n",
    "stars_csv = stars.merge(proper, on='proper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIP_csv = HIP_csv.append(GL_csv)\n",
    "HIP_csv = HIP_csv.append(HD_csv)\n",
    "HIP_csv = HIP_csv.append(stars_csv)\n",
    "HIP_csv = HIP_csv.append(HR_csv)\n",
    "HIP_csv['all_names'] = HIP_csv['all_names'].astype(str)\n",
    "HIP_csv = HIP_csv.drop_duplicates('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIP_csv['dist'] = HIP_csv['dist'].replace(100000, np.nan)\n",
    "HIP_csv['dist'] = HIP_csv.fillna(HIP_csv['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new estimates roughly 1 in 4 sunlike stars have planets, adjusting for how much data will be lost when dropping null values \n",
    "data = HIP_csv.append(star_csv.sample(3000, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = ['HE', 'NEP', 'CE', 'CN', 'CJ', 'HN', 'HSE', 'JUP', 'SE', 'WJ', 'WN', 'WSE', 'children']\n",
    "for item in list_:\n",
    "    data[item] = data[item].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['children', 'ra', 'dec', 'dist', 'pmra', 'pmdec', 'rv', 'mag', 'absmag', 'spect', 'ci', 'x', 'y', 'z', 'vx', 'vy', 'vz', 'rarad', \n",
    "             'decrad', 'pmrarad', 'pmdecrad','comp_primary', 'lum','HE', 'NEP', 'CE', 'CN', 'CJ', 'HN', 'HSE', 'JUP', 'SE', 'WJ', 'WN', 'WSE']].copy()\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['temp_class'] = data['spect'].str[:1]\n",
    "data['temp_class'] = data['temp_class'].fillna('nan')\n",
    "\n",
    "data['heat_class'] = data['spect'].str[1:2]\n",
    "data['heat_class'] = data['heat_class'].fillna('nan')\n",
    "\n",
    "data['harv_class'] = data['spect'].str[:2]\n",
    "data['harv_class'] = data['harv_class'].fillna('nan')\n",
    "\n",
    "data['lum_class'] = data['spect'].str[2:]\n",
    "data['lum_class'] = data['lum_class'].fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()\n",
    "data = pd.get_dummies(data, columns=['temp_class'], prefix='_y')\n",
    "data = pd.get_dummies(data, columns=['heat_class'], prefix='_x')\n",
    "data = pd.get_dummies(data, columns=['lum_class'], prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['I'] = data['_.5Ia'] + data['_.5Ib'] + data['_/B8Ib'] + data['_Ia'] + data['_Ib'] + data['_Ib/II']  + data['_.5Iab:ne'] + data['_Iab:var']\n",
    "data['I'] = data['I'] + data['_-G2Ie'] + data['_Ib-II'] + data['_Ia0:'] + data['_Iab:'] + data['_Ib+...'] + data['_-F8Ib'] + data['_Ia/ab'] + data['_Iab']\n",
    "\n",
    "data['II'] = data['_Ib/II'] + data['_Ib-II'] + data['_/B9II/III'] + data['_/K0II'] + data['_II'] + data['_II-III'] + data['_II/III'] + data['_IICNp...']\n",
    "data['II'] = data['_IIb'] + data['II'] + data['_IIp...'] + data['_II/IIICN'] + data['_IICN...'] + data['_/2II/III+A'] + data['_/F2III']\n",
    "data['II'] = data['II'] + data['_II + A/F'] + data['_II+...']\n",
    "\n",
    "data['III'] = data['_.5III'] + data['_.5III:'] + data['_/A3III'] + data['_/B8III'] + data['_/B9II/III'] + data['_/B9III/IV'] + data['_/A8III']\n",
    "data['III'] = data['III'] + data['_/G5III'] + data['_/G8III'] + data['_/G8III:'] + data['_/K0III'] + data['_/K0III:'] + data['_/K1III']\n",
    "data['III'] = data['III'] + data['_/K1III+..'] + data['_/K2III'] + data['_/K3III'] + data['_/K3III:'] + data['_/K4III'] + data['_/K4III:'] \n",
    "data['III'] = data['III'] + data['_/M0III'] + data['_/M1III'] + data['_/M3III'] + data['_:III:'] + data['_III+...'] + data['_II-III'] + data['_/K5III']\n",
    "data['III'] = data['III'] + data['_II/IIICNV:'] + data['_III'] + data['_III + (F)'] + data['_III-IV'] + data['_III...'] + data['_III/IV'] \n",
    "data['III'] = data['III'] + data['_III:'] + data['_IIICN...'] + data['_IIICNII'] + data['_IIICNp...'] + data['_IIIb'] + data['_IIIp'] + data['_IIIvar']\n",
    "data['III'] = data['III'] + data['_/M2III'] + data['_II/IIICN'] + data['_III-IV SB'] + data['_III/IVCN.'] + data['_IIIsp...'] + data['_.5III/IV']\n",
    "data['III'] = data['III'] + data['_/2II/III+A'] + data['_/F5III'] + data['_/G6III'] + data['_/K0III+..'] + data['_/K0IIICNp']\n",
    "data['III'] = data['III'] + data['_/K2III:'] + data['_/M1III:'] + data['_III comp']\n",
    "\n",
    "data['IV'] = data['_.5IV'] + data['_/B9III/IV'] + data['_/A3IV'] + data['_/A3IV/V'] + data['_/A7IV'] + data['_/F2IV'] + data['_/F2IV/V']\n",
    "data['IV'] = data['IV'] + data['_/F7IV/V'] + data['_/K0IV/V'] + data['_/K1IV'] + data['_III-IV'] + data['_/K1IV/V:'] + data['_IV...']\n",
    "data['IV'] = data['IV'] + data['_III/IV']  + data['_IV'] + data['_IV-V'] + data['_IV/V'] + data['_IV: (+F/G)'] + data['_III/IVCN.']\n",
    "data['IV'] = data['IV'] + data['_IV:pe...'] + data['_IVn'] + data['_.5IV-V'] + data['_/F3IV'] + data['_/F5IV'] + data['_III-IV SB']\n",
    "data['IV'] = data['IV'] + data['_IVne+...'] + data['_.5III/IV'] + data['_/A4IV'] + data['_/B3IV'] + data['_/F3IV/V'] + data['_/F5IV/V']\n",
    "data['IV'] = data['IV'] + data['_/F6IV/V'] + data['_/F8IV+...'] + data['_/G8IV/V'] + data['_:IVp'] + data['_IVCN...']\n",
    "\n",
    "data['V'] = data['_ V'] + data['_.5V'] + data['_.5Ve'] + data['_.5Vn'] + data['_/A1V'] + data['_/A2V'] + data['_/A3IV/V'] + data['_Vm'] + data['_/K1IV/V:']\n",
    "data['V'] = data['V'] + data['_/A3V'] + data['_/A3V+...'] + data['_V+...'] + data['_/B3V'] + data['_/B8V'] + data['_/B9V'] + data['_Vp...']\n",
    "data['V'] = data['V'] + data['_/F2IV/V'] + data['_/F3V'] + data['_/F5V'] + data['_/F6V'] + data['_/F7IV/V'] + data['_/F7V'] + data['_/F8V']\n",
    "data['V'] = data['V'] + data['_/G0V'] + data['_/G1V'] + data['_/G2V'] + data['_/G3V'] + data['_/G5V'] + data['_/G6V'] + data['_/G8V'] + data['_/B9.5V']\n",
    "data['V'] = data['V'] + data['_/K0IV/V'] + data['_/K0V'] + data['_/K1V'] + data['_/K3V'] + data['_/M2V'] + data['_:V...'] + data['_IV-V'] + data['_V']\n",
    "data['V'] = data['V'] + data['_V + G/K'] + data['_V+...'] + data['_V-VI'] + data['_V...'] + data['_V:'] + data['_V:n'] + data['_V:pe'] + data['_VCN...']\n",
    "data['V'] = data['V'] + data['_Ve'] + data['_Ve+...'] + data['_Vn'] + data['_Vne'] + data['_Vp'] + data['_Vw...'] + data['_V comp'] + data['_.5IV-V']\n",
    "data['V'] = data['V'] + data['_Vvar'] + data['_/B5V'] + data['_/F2V'] + data['_/F3IV/V'] + data['_/F5IV/V'] + data['_/F6IV/V'] + data['_/G8IV/V']\n",
    "data['V'] = data['V'] + data['_/K3V:+...'] + data['_V comp SB'] + data['_Vpe'] + data['_Vws']\n",
    "\n",
    "data['VI'] = data['_V-VI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['...'] = data['_+...'] + data['_..'] + data['_...'] + data['_w...'] + data['_sp...'] + data['_V...'] + data['_p...'] + data['_m...']\n",
    "data['...'] = data['...'] + data['_Vw...'] + data['_Ve+...'] + data['_IV:pe...'] + data['_III...'] + data['_:+...'] + data['_IVne+...']\n",
    "data['...'] = data['...'] + data['_IICNp...'] + data['_III+...'] + data['_/K0p...'] + data['_/G0Vs...'] + data['_IIIsp...'] + data['_Ib+...']\n",
    "data['...'] = data['...'] + data['_:w...'] + data['_:V...'] + data['_:III:+...'] + data['_:+...'] + data['_/K1III+..'] + data['_/G5Vw...'] \n",
    "data['...'] = data['...'] + data['_/A3V+...'] + data['_/G8w...'] + data['_IIICN...'] + data['_IIIp...'] + data['_/F8IV+...']\n",
    "data['...'] = data['...'] + data['_V+...'] + data['_VCN...'] + data['_IIp...'] + data['_Vp...'] + data['_IICN...'] + data['_IV...']\n",
    "data['...'] = data['...'] + data['_/K0III+..'] + data['_/K3V:+...'] + data['_:Vw...'] + data['_II+...'] + data['_IVCN...']\n",
    "\n",
    "data[':'] = data['_.5III:'] + data['_/G8III:'] + data['_/K0III:'] + data['_IV:pe...'] + data['_:+...'] + data['_:III:+...'] + data['_:w...'] + data['_:V...']\n",
    "data[':'] = data[':'] + data['_/K3III:'] + data['_/K4III:'] + data['_:'] + data['_II/IIICNV:'] + data['_III:'] + data['_:III:'] + data['_Ia0:']\n",
    "data[':'] = data[':'] + data['_IV: (+F/G)'] + data['_IV:pe...'] + data['_O:'] + data['_V:'] + data['_V:n'] + data['_V:pe'] + data['_/K1IV/V:']\n",
    "data[':'] = data[':'] + data['_Iab:'] + data['_.5Iab:ne'] + data['_/K2III:'] + data['_/K3V:+...'] + data['_/M1III:'] + data['_:IVp'] + data['_:Vw...']\n",
    "data[':'] = data[':'] + data['_F:']\n",
    "\n",
    "data['+'] = data['_+...'] + data['_/A3V+...'] + data['_/K0V + A/F'] + data['_Ve+...'] + data['_:III:+...'] + data['_/2II/III+A']\n",
    "data['+'] = data['+'] + data['_III+...'] + data['_:+...'] + data['_/K1III+..'] + data['_V + G/K'] + data['_/K3V:+...'] + data['_II + A/F']\n",
    "data['+'] = data['+'] + data['_V+...']  + data['_IVne+...'] + data['_Ib+...'] + data['_/F8IV+...'] + data['_/K0III+..'] + data['_II+...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['0'] = data['_x_0'] + data['_/G0V'] + data['_/G0Vs...'] + data['_/K0II'] + data['_/K0III'] + data['_/K0III:'] + data['_/K0IV/V'] + data['_/K0V']\n",
    "data['0'] = data['0'] + data['_/K0V + A/F'] + data['_/K0p...'] + data['_/M0III'] + data['_0'] + data['_Ia0:'] + data['_/K0III+..']\n",
    "data['0'] = data['0'] + data['_/K0IIICNp']\n",
    "data['1'] = data['_x_1'] + data['_/A1V'] + data['_/G1V'] + data['_/G2V'] + data['_/K1III'] + data['_/K1III+..'] + data['_/K1IV']\n",
    "data['1'] = data['1']+ data['_/M1III'] + data['_/K1IV/V:'] + data['_/M1III:']\n",
    "data['2'] = data['_x_2'] + data['_-G2Ie'] + data['_/A2V'] + data['_/F2IV'] + data['_/F2IV/V'] + data['_/K2III'] + data['_/M2V'] + data['_G2']\n",
    "data['2'] = data['2'] + data['_/M2III'] + data['_/2II/III+A'] + data['_/F2III'] + data['_/F2V'] + data['_/K2III:']\n",
    "data['3'] = data['_x_3'] + data['_/A3III'] + data['_/A3IV'] + data['_/A3IV/V'] + data['_/A3V'] + data['_/A3V+...'] + data['_/B3V'] + data['_/F3']\n",
    "data['3'] = data['3'] + data['_/F3V'] + data['_/G2V'] + data['_/K3III'] + data['_/K3III:'] + data['_/K3V'] + data['_/M3III']\n",
    "data['3'] = data['3'] + data['_3'] + data['_3   :'] + data['_/F3IV'] + data['_/B3IV'] + data['_/F3IV/V'] + data['_/K3V:+...']\n",
    "data['4'] = data['_x_4'] + data['_/K4'] + data['_/K4III'] + data['_/K4III:'] + data['_/A4IV']\n",
    "data['5'] = data['_x_5'] + data['_/F5V'] + data['_/G5III'] + data['_/G5V'] + data['_/G5Vw...'] + data['_5'] + data['_/F5IV'] + data['_/K5III']\n",
    "data['5'] = data['5'] + data['_/B5V'] + data['_/F5III'] + data['_/F5IV/V']\n",
    "data['6'] = data['_x_6'] + data['_/F6V'] + data['_/G6V'] + data['_6'] + data['_6 (SB1)'] + data['_/F6IV/V'] + data['_/G6III']\n",
    "data['7'] = data['_x_7'] + data['_/A7IV'] + data['_/F7IV/V'] + data['_/F7V'] + data['_7'] + data['_e-M7e']\n",
    "data['8'] = data['_x_8'] + data['_/B8III'] + data['_/B8Ib'] + data['_/B8V'] + data['_/F8V'] + data['_/G8III'] + data['_/G8III:'] + data['_/F8IV+...']\n",
    "data['8'] = data['_x_8'] + data['_/G8V'] + data['_/G8w...'] + data['_/O8'] + data['_8'] + data['_e-M8e'] + data['_/A8III'] + data['_-F8Ib']\n",
    "data['8'] = data['8'] + data['_/G8IV/V']\n",
    "data['9'] = data['_x_9'] + data['_/B9II/III'] + data['_/B9III/IV'] + data['_/B9V'] + data['_9'] + data['_9?'] + data['_e-M9e'] + data['_/B9.5V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['A'] = data['_y_A'] + data['_x_A'] + data['_/A1V'] + data['_/A2V'] + data['_/A3III'] + data['_/A3IV'] + data['_/A3IV/V'] + data['_/A3V'] \n",
    "data['A'] = data['A'] + data['_/A7IV'] + data['_/A3V+...'] + data['_/A8III'] + data['_/A4IV']\n",
    "data['B'] = data['_/B3V'] + data['_/B8III'] + data['_/B8Ib'] + data['_/B8V'] + data['_/B9II/III'] + data['_/B9III/IV']\n",
    "data['B'] = data['B'] + data['_/B9V'] + data['_y_B'] + data['_/B3IV'] + data['_/B5V']\n",
    "data['C'] = data['_y_C'] + data['_x_C']\n",
    "data['E'] = data['_-G2Ie'] + data['_.5Ve']\n",
    "data['F'] = data['_/F2IV'] + data['_/F2IV/V'] + data['_/F3'] + data['_/F3V'] + data['_/F5V'] + data['_/F6V'] + data['_/F6IV/V'] + data['_/F8IV+...'] \n",
    "data['F'] = data['F'] + data['_/F7IV/V'] + data['_/F7V'] + data['_/F8V'] + data['_y_F'] + data['_/F3IV'] + data['_/F5IV'] + data['_/F2III']\n",
    "data['F'] = data['F'] + data['_-F8Ib'] + data['_/F2III'] + data['_/F2V'] + data['_/F3IV/V'] + data['_/F5III'] + data['_/F5IV/V'] + data['_/F2V']\n",
    "data['F'] = data['F'] + data['_/F3IV/V'] + data['_/F5III'] + data['_/F5IV/V'] + data['_/F6IV/V'] + data['_/F8IV+...'] + data['_F:']\n",
    "data['G'] = data['_y_G'] + data['_-G2Ie'] + data['_/G0V'] + data['_/G1V'] + data['_/G2V'] + data['_/G3V'] + data['_/G5III'] + data['_/G5V']  + data['_/G5Vw...']  \n",
    "data['G'] = data['G'] + data['_/G6V']  + data['_/G8III']  + data['_/G8V']  + data['_/G8w...']  + data['_G2'] + data['_/G6III'] + data['_/G8IV/V']\n",
    "data['K'] = data['_y_K'] + data['_x_K'] + data['_/K0II']  + data['_/K0III'] + data['_/K0III:'] + data['_/K0IV/V'] + data['_/K0V'] + data['_/K0V + A/F']\n",
    "data['K'] = data['K'] + data['_/K0p...'] + data['_/K1III'] + data['_/K1III+..'] + data['_/K1IV'] + data['_/K1V'] + data['_/K2III'] + data['_/K1IV/V:']\n",
    "data['K'] = data['K'] + data['_/K3III'] + data['_/K3III:'] + data['_/K3V'] + data['_/K4'] + data['_/K4III'] + data['_/K4III:'] + data['_y_k']\n",
    "data['K'] = data['K'] + data['_/K5III'] + data['_/K0IIICNp'] + data['_/K2III:'] + data['_/K3V:+...']\n",
    "data['N'] = data['_y_N'] + data['_x_N'] \n",
    "data['M'] = data['_y_M'] + data['_x_M'] + data['_/M0III'] + data['_/M1III']  + data['_/M2V'] + data['_/M3III'] + data['_e-M8e'] + data['_e-M9e']\n",
    "data['M'] = data['M'] + data['_/M2III'] + data['_e-M7e'] + data['_/M1III:']\n",
    "data['RD'] = data['_y_R'] + data['_x_d']\n",
    "data['S'] = data['_y_s'] + data['_x_s']\n",
    "data['W'] = data['_y_W'] \n",
    "data['O'] = data['_y_O'] + data['_/O8'] + data['_O:']\n",
    "data['D'] = data['_y_D']\n",
    "\n",
    "data['n'] =  data['_.5Vn'] + data['_IVn'] + data['_V:n'] + data['_Vn'] + data['_Vne'] + data['_x_n'] + data['_IVne+...'] + data['_npe'] + data['_.5Iab:ne']\n",
    "data['e'] = data['_IV:pe...'] + data['_V:pe'] + data['_Ve'] + data['_Ve+...'] + data['_Vne'] + data['_e'] + data['_e-M7e'] + data['_.5Iab:ne']\n",
    "data['e'] = data['e'] + data['_e-M8e'] + data['_e-M9e']  + data['_x_e'] + data['_.5e'] + data['_IVne+...'] + data['_Vpe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_:', '_:+...', '_:III:', '_:III:+...', '_:IVp', '_:V...', '_:Vw...',\n",
       "       '_:w...', '_F:', '_G2', '_II', '_II + A/F', '_II SB', '_II+...',\n",
       "       '_II-III', '_II/III', '_II/IIICN', '_II/IIICNV:', '_IICN...',\n",
       "       '_IICNp...', '_III', '_III + (F)', '_III comp', '_III+...', '_III-IV',\n",
       "       '_III-IV SB', '_III...', '_III/IV', '_III/IVCN.', '_III/IVm..', '_III:',\n",
       "       '_IIICN...', '_IIICNII', '_IIICNp...', '_IIIb', '_IIIp', '_IIIp...',\n",
       "       '_IIIsp...', '_IIIvar', '_IIb', '_IIp...', '_IV', '_IV-V', '_IV...',\n",
       "       '_IV/V', '_IV: (+F/G)', '_IV:pe...', '_IVCN...', '_IVn', '_IVne+...',\n",
       "       '_Ia', '_Ia/ab', '_Ia0:', '_Iab', '_Iab:', '_Iab:var', '_Ib', '_Ib+...',\n",
       "       '_Ib-II', '_Ib/II', '_O:', '_Sv', '_V', '_V + G/K', '_V comp',\n",
       "       '_V comp SB', '_V+...', '_V-VI', '_V...', '_V:', '_V:n', '_V:pe',\n",
       "       '_VCN...', '_Ve', '_Ve+...', '_Vm', '_Vn', '_Vne', '_Vp', '_Vp...',\n",
       "       '_Vpe', '_Vs', '_Vvar', '_Vw...', '_Vws', '_e', '_e-M7e', '_e-M8e',\n",
       "       '_e-M9e', '_ev', '_m', '_m...', '_mp', '_npe', '_p', '_p...', '_psh',\n",
       "       '_sp...', '_w...', '_wp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['children', 'ra', 'dec', 'dist', 'pmra', 'pmdec', 'rv', 'mag', 'absmag', \n",
    "             'ci', 'x', 'y', 'z', 'vx', 'vy', 'vz', 'rarad', 'decrad', 'pmrarad', 'pmdecrad',\n",
    "             'comp_primary', 'lum', 'HE', 'NEP', 'CE', 'CN', 'CJ', 'HN', 'HSE', 'JUP', 'SE',\n",
    "             'WJ', 'WN', 'WSE', 'I', 'II', 'III', 'IV', 'V', 'VI', '...', ':', '+', '0', '1',\n",
    "             '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'E', 'F', 'G', 'K', 'N',\n",
    "             'M', 'RD', 'S', 'W', 'O', 'D', 'n', 'e'], 1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['children', 'ra', 'dec', 'dist', 'pmra', 'pmdec', 'rv', 'mag', 'absmag', \n",
    "             'ci', 'x', 'y', 'z', 'vx', 'vy', 'vz', 'rarad', 'decrad', 'pmrarad', 'pmdecrad',\n",
    "             'comp_primary', 'lum', 'HE', 'NEP', 'CE', 'CN', 'CJ', 'HN', 'HSE', 'JUP', 'SE',\n",
    "             'WJ', 'WN', 'WSE', 'I', 'II', 'III', 'IV', 'V', 'VI', '...', ':', '+', '0', '1',\n",
    "             '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'E', 'F', 'G', 'K', 'N',\n",
    "             'M', 'RD', 'S', 'W', 'O', 'D', 'n', 'e']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ra'] = data['ra'].astype(float)\n",
    "data['dec'] = data['dec'].astype(float)\n",
    "data['dist'] = data['dist'].astype(float)\n",
    "data['pmra'] = data['pmra'].astype(float)\n",
    "data['pmdec'] = data['pmdec'].astype(float)\n",
    "data['rv'] = data['rv'].astype(float)\n",
    "data['mag'] = data['mag'].astype(float)\n",
    "data['absmag'] = data['absmag'].astype(float)\n",
    "data['x'] = data['x'].astype(float)\n",
    "data['y'] = data['y'].astype(float)\n",
    "data['z'] = data['z'].astype(float)\n",
    "data['vx'] = data['vx'].astype(float)\n",
    "data['vz'] = data['vz'].astype(float)\n",
    "data['vy'] = data['vy'].astype(float)\n",
    "data['rarad'] = data['rarad'].astype(float)\n",
    "data['decrad'] = data['decrad'].astype(float)\n",
    "data['pmrarad'] = data['pmrarad'].astype(float)\n",
    "data['pmdecrad'] = data['pmdecrad'].astype(float)\n",
    "data['comp_primary'] = data['comp_primary'].astype(float)\n",
    "data['lum'] = data['lum'].astype(float)\n",
    "data['ci'] = data['ci'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['I'] = data['I'].replace(2,1)\n",
    "data['V'] = data['V'].replace(2,1)\n",
    "data['...'] = data['...'].replace(2,1)\n",
    "data[':'] = data[':'].replace(2,1)\n",
    "data['0'] = data['0'].replace(2,1)\n",
    "data['1'] = data['1'].replace(2,1)\n",
    "data['2'] = data['2'].replace(2,1)\n",
    "data['9'] = data['9'].replace(2,1)\n",
    "data['B'] = data['B'].replace(2,1)\n",
    "data['D'] = data['D'].replace(2,1)\n",
    "data['F'] = data['F'].replace({2:1, 3:1})\n",
    "data['G'] = data['G'].replace(2,1)\n",
    "data['M'] = data['M'].replace(2,1)\n",
    "data['O'] = data['O'].replace(2,1)\n",
    "data['N'] = data['N'].replace(2,1)\n",
    "data['n'] = data['n'].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('scrubbed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4239\n",
       "1       2\n",
       "Name: N, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['N'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
